

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/blog/img/favicon.jpg">
  <link rel="icon" href="/blog/img/favicon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Azure">
  <meta name="keywords" content="">
  
    <meta name="description" content="论文">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch 快速上手">
<meta property="og:url" content="https://yoonalis.github.io/blog/2023/11/22/PyTorch%20handbook/index.html">
<meta property="og:site_name" content="Azure&#39;s blog">
<meta property="og:description" content="论文">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yoonalis.github.io/blog/img/pytorch.png">
<meta property="article:published_time" content="2023-11-22T13:37:24.136Z">
<meta property="article:modified_time" content="2023-11-30T13:33:39.930Z">
<meta property="article:author" content="Azure">
<meta property="article:tag" content="论文、深度学习、pytorch">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://yoonalis.github.io/blog/img/pytorch.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>PyTorch 快速上手 - Azure&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/blog/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/blog/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/blog/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"yoonalis.github.io","root":"/blog/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/blog/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/blog/js/utils.js" ></script>
  <script  src="/blog/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/blog/">
      <strong>Azure</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/album/">
                <i class="iconfont icon-images"></i>
                album
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/blog/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="PyTorch 快速上手"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-11-22 21:37" pubdate>
          2023年11月22日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          34k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          286 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">PyTorch 快速上手</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="PyTorch-handbook"><a href="#PyTorch-handbook" class="headerlink" title="PyTorch handbook"></a>PyTorch handbook</h1><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://github.com/zergtant/pytorch-handbook">https://github.com/zergtant/pytorch-handbook</a></p>
</blockquote>
<h2 id="1-torch"><a href="#1-torch" class="headerlink" title="1 torch"></a>1 torch</h2><ul>
<li>引入</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br></code></pre></td></tr></table></figure>

<p>使用</p>
<table>
<thead>
<tr>
<th>语句</th>
<th>解释</th>
<th>输出</th>
</tr>
</thead>
<tbody><tr>
<td>x &#x3D; torch.&#x3D;&#x3D;empty&#x3D;&#x3D;(5, 3)</td>
<td>创建一个 5x3 矩阵, 但是未初始化</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124213017259-20231124%2021:30:18.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124213017259" style="zoom:50%;" /></td>
</tr>
<tr>
<td>x &#x3D; torch.&#x3D;&#x3D;rand&#x3D;&#x3D;(5, 3)</td>
<td>创建一个随机初始化的矩阵</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124213050669-20231124%2021:30:50.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124213050669" style="zoom:50%;" /></td>
</tr>
<tr>
<td>x &#x3D; torch.&#x3D;&#x3D;zeros&#x3D;&#x3D;(5, 3, dtype&#x3D;torch.long)</td>
<td>创建一个0填充的矩阵，数据类型为long</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124213127733-20231124%2021:31:27.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124213127733" style="zoom:50%;" /></td>
</tr>
<tr>
<td>x &#x3D; torch.&#x3D;&#x3D;tensor&#x3D;&#x3D;([5.5, 3])</td>
<td>创建tensor并使用现有数据初始化</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124213212757-20231124%2021:32:12.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124213212757" style="zoom:50%;" /></td>
</tr>
<tr>
<td>x &#x3D; x.&#x3D;&#x3D;new_ones&#x3D;&#x3D;(5, 3, dtype&#x3D;torch.double)   <br />x &#x3D; torch.&#x3D;&#x3D;randn_like&#x3D;&#x3D;(x, dtype&#x3D;torch.float)</td>
<td>根据现有的张量创建张量</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124213353480-20231124%2021:33:53.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124213353480" style="zoom:50%;" /></td>
</tr>
<tr>
<td>x.size()</td>
<td>使用size方法与Numpy的shape属性返回的相同</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124213559942-20231124%2021:36:00.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124213559942" style="zoom:50%;" /></td>
</tr>
<tr>
<td>x + y<br />torch.add(x, y)<br />torch.add(x, y, out&#x3D;result)<br />y.add_(x) # adds x to y</td>
<td>加法<br />任何 以<code>_</code> 结尾的操作都会用结果替换原变量. 例如: <code>x.copy_(y)</code>, <code>x.t_()</code>, 都会改变 <code>x</code>.</td>
<td></td>
</tr>
<tr>
<td>x[:, 1]</td>
<td>获取第一列数据</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124214007532-20231124%2021:40:07.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124214007532" style="zoom:50%;" /></td>
</tr>
<tr>
<td>x &#x3D; torch.randn(4, 4)<br/>y &#x3D; x.view(16)<br/>z &#x3D; x.view(-1, 8)</td>
<td>torch.view 与Numpy的reshape类似</td>
<td><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231124214159976-20231124%2021:42:00.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231124214159976" style="zoom:50%;" /></td>
</tr>
</tbody></table>
<h3 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h3><p>Tensor的基本数据类型有五种：</p>
<ul>
<li>32位浮点型：torch.FloatTensor。 (默认)</li>
<li>64位整型：torch.LongTensor。</li>
<li>32位整型：torch.IntTensor。</li>
<li>16位整型：torch.ShortTensor。</li>
<li>64位浮点型：torch.DoubleTensor。</li>
</ul>
<p>除以上数字类型外，还有 byte和chart型</p>
<h2 id="2-numpy和torch的转换"><a href="#2-numpy和torch的转换" class="headerlink" title="2 numpy和torch的转换"></a>2 numpy和torch的转换</h2><ul>
<li>将一个Torch Tensor转换为NumPy数组</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.ones(<span class="hljs-number">5</span>) <span class="hljs-comment"># tensor([1., 1., 1., 1., 1.])</span><br>b = a.numpy() <span class="hljs-comment"># [1. 1. 1. 1. 1.]</span><br></code></pre></td></tr></table></figure>

<ul>
<li>NumPy Array 转化成 Torch Tensor</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a = np.ones(<span class="hljs-number">5</span>)<br>b = torch.from_numpy(a)<br></code></pre></td></tr></table></figure>

<ul>
<li>使用<code>.to</code> 方法 可以将Tensor移动到任何设备中</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>)          <span class="hljs-comment"># a CUDA 设备对象</span><br>    y = torch.ones_like(x, device=device)  <span class="hljs-comment"># 直接从GPU创建张量</span><br>    x = x.to(device)                       <span class="hljs-comment"># 或者直接使用``.to(&quot;cuda&quot;)``将张量移动到cuda中</span><br></code></pre></td></tr></table></figure>

<h2 id="3-自动求导机制"><a href="#3-自动求导机制" class="headerlink" title="3 自动求导机制"></a>3 自动求导机制</h2><h3 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h3><p>PyTorch 中所有神经网络的核心是 <code>autograd</code> 包。</p>
<p><code>autograd</code>包为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。</p>
<p><code>torch.Tensor</code>是这个包的核心类。如果设置 <code>.requires_grad</code> 为 <code>True</code>，那么将会追踪所有对于该张量的操作。 当完成计算后通过调用 <code>.backward()</code>，自动计算所有的梯度， 这个张量的所有梯度将会自动积累到 <code>.grad</code> 属性。</p>
<p>要阻止张量跟踪历史记录，可以调用<code>.detach()</code>方法将其与计算历史记录分离，并禁止跟踪它将来的计算记录。</p>
<p>为了防止跟踪历史记录（和使用内存），可以将代码块包装在<code>with torch.no_grad()：</code>中。 在评估模型时特别有用，因为模型可能具有<code>requires_grad = True</code>的可训练参数，但是我们不需要梯度计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>x = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, requires_grad=<span class="hljs-literal">True</span>)<br>y = x + <span class="hljs-number">2</span><br><span class="hljs-comment"># 结果y已经被计算出来了，所以，grad_fn已经被自动生成了。</span><br>y.grad_fn <span class="hljs-comment"># &lt;AddBackward0 object at 0x000002004F7CC248&gt;</span><br></code></pre></td></tr></table></figure>

<h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><h4 id="例子1：梯度计算"><a href="#例子1：梯度计算" class="headerlink" title="例子1：梯度计算"></a>例子1：梯度计算</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, requires_grad=<span class="hljs-literal">True</span>)<br>y = x + <span class="hljs-number">2</span><br>z = y * y * <span class="hljs-number">3</span><br>out = z.mean()<br>out.backward()<br><span class="hljs-built_in">print</span>(x)<br><span class="hljs-comment"># tensor([[1., 1.],</span><br><span class="hljs-comment">#         [1., 1.]], requires_grad=True)</span><br><span class="hljs-built_in">print</span>(x.grad)<br><span class="hljs-comment"># tensor([[4.5000, 4.5000],</span><br><span class="hljs-comment">#         [4.5000, 4.5000]])</span><br></code></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231126164522065-20231126%2016:45:22.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231126164522065"></p>
<h4 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.randn(<span class="hljs-number">3</span>, requires_grad=<span class="hljs-literal">True</span>)<br><br>y = x * <span class="hljs-number">2</span><br><span class="hljs-keyword">while</span> y.data.norm() &lt; <span class="hljs-number">1000</span>:<br>    y = y * <span class="hljs-number">2</span><br><br><span class="hljs-built_in">print</span>(y) <span class="hljs-comment"># tensor([ 293.4463,   50.6356, 1031.2501], grad_fn=&lt;MulBackward0&gt;)</span><br></code></pre></td></tr></table></figure>

<p>在这个情形中，<code>y</code>不再是个标量。<code>torch.autograd</code>无法直接计算出完整的雅可比行列，但是如果我们只想要vector-Jacobian product，只需将向量作为参数传入<code>backward</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">gradients = torch.tensor([<span class="hljs-number">0.1</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.0001</span>], dtype=torch.<span class="hljs-built_in">float</span>)<br>y.backward(gradients)<br><br><span class="hljs-built_in">print</span>(x.grad) <span class="hljs-comment"># tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])</span><br></code></pre></td></tr></table></figure>

<p>如果<code>.requires_grad=True</code>但是你又不希望进行autograd的计算， 那么可以将变量包裹在 <code>with torch.no_grad()</code>中:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(x.requires_grad) <span class="hljs-comment"># True</span><br><span class="hljs-built_in">print</span>((x ** <span class="hljs-number">2</span>).requires_grad) <span class="hljs-comment"># True</span><br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-built_in">print</span>((x ** <span class="hljs-number">2</span>).requires_grad)<span class="hljs-comment"># False</span><br></code></pre></td></tr></table></figure>

<blockquote>
<p>官方文档：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/autograd.html">https://pytorch.org/docs/stable/autograd.html</a></p>
</blockquote>
<h4 id="例子3：简单的自动求导"><a href="#例子3：简单的自动求导" class="headerlink" title="例子3：简单的自动求导"></a>例子3：简单的自动求导</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>x = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, requires_grad=<span class="hljs-literal">True</span>)<br>y = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, requires_grad=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># PyTorch会自动追踪和记录对与张量的所有操作，当计算完成后调用.backward()方法自动计算梯度并且将计算结果保存到grad属性中。</span><br>z=torch.<span class="hljs-built_in">sum</span>(x+y) <span class="hljs-comment"># tensor(25.6487, grad_fn=&lt;SumBackward0&gt;)</span><br><br>z.backward()<br><span class="hljs-built_in">print</span>(x.grad,y.grad)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231126212314382-20231126%2021:23:14.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231126212314382" style="zoom:50%;" />

<p>如果Tensor类表示的是一个标量（即它包含一个元素的张量），则不需要为backward()指定任何参数，但是如果它有更多的元素，则需要指定一个gradient参数，它是形状匹配的张量。 以上的 <code>z.backward()</code>相当于是<code>z.backward(torch.tensor(1.))</code>的简写。 这种参数常出现在图像分类中的单标签分类，输出一个标量代表图像的标签。</p>
<h4 id="例子4：复杂的自动求导"><a href="#例子4：复杂的自动求导" class="headerlink" title="例子4：复杂的自动求导"></a>例子4：复杂的自动求导</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, requires_grad=<span class="hljs-literal">True</span>)<br>y = torch.rand(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, requires_grad=<span class="hljs-literal">True</span>)<br>z= x**<span class="hljs-number">2</span>+y**<span class="hljs-number">3</span> <span class="hljs-comment"># z是一个5*5的张量</span><br><br><span class="hljs-comment">#我们的返回值不是一个标量，所以需要输入一个大小相同的张量作为参数，这里我们用ones_like函数根据x生成一个张量</span><br>z.backward(torch.ones_like(x))<br><span class="hljs-built_in">print</span>(x.grad) <span class="hljs-comment"># 返回一个5*5的张量</span><br></code></pre></td></tr></table></figure>



<h2 id="4-神经网络"><a href="#4-神经网络" class="headerlink" title="4 神经网络"></a>4 神经网络</h2><p>使用torch.nn包来构建神经网络。</p>
<p>上一讲已经讲过了<code>autograd</code>，<code>nn</code>包依赖<code>autograd</code>包来定义模型并求导。 一个<code>nn.Module</code>包含各个层和一个<code>forward(input)</code>方法，该方法返回<code>output</code>。</p>
<p>例如</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231126172550751-20231126%2017:25:50.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231126172550751"></p>
<p>它是一个简单的前馈神经网络，它接受一个输入，然后一层接着一层地传递，最后输出计算的结果。</p>
<p>神经网络的典型训练过程如下：</p>
<ol>
<li>定义包含一些可学习的参数(或者叫权重)神经网络模型； </li>
<li>在数据集上迭代； </li>
<li>通过神经网络处理输入； </li>
<li>计算损失(输出结果和正确值的差值大小)；</li>
<li>将梯度反向传播回网络的参数； </li>
<li>更新网络的参数，主要使用如下简单的更新原则： <code>weight = weight - learning_rate * gradient</code></li>
</ol>
<h3 id="定义一个网络：nn"><a href="#定义一个网络：nn" class="headerlink" title="定义一个网络：nn"></a>定义一个网络：nn</h3><p>torch.nn是专门为神经网络设计的模块化接口。nn构建于 Autograd之上，可用来定义和运行神经网络。</p>
<p>除了nn别名以外，我们还引用了nn.functional，这个包中包含了神经网络中使用的一些常用函数，这些函数的特点是，不具有可学习的参数(如ReLU，pool，DropOut等)，这些函数可以放在构造函数中，也可以不放，但是这里建议不放。</p>
<p>一般情况下我们会<strong>将nn.functional 设置为大写的F</strong>，这样缩写方便调用。</p>
<p>PyTorch中已经为我们准备好了现成的网络模型，只要继承nn.Module，并实现它的forward方法，PyTorch会根据autograd，自动实现backward函数，在forward函数中可使用任何tensor支持的函数，还可以使用if、for循环、print、log等Python语法，写法和标准的Python写法一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># nn.Module子类的函数必须在构造函数中执行父类的构造函数</span><br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        <span class="hljs-comment"># 卷积层 &#x27;1&#x27;表示输入图片为单通道， &#x27;6&#x27;表示输出通道数，&#x27;3&#x27;表示卷积核为3*3</span><br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-comment"># an affine operation: y = Wx + b</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        <span class="hljs-comment"># 线性层，输入84个特征，输出10个特征</span><br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-comment"># 正向传播</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>      	<span class="hljs-comment"># 卷积 -&gt; 激活 -&gt; 池化 </span><br>        <span class="hljs-comment"># Max pooling over a (2, 2) window</span><br>        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>        <span class="hljs-comment"># If the size is a square you can only specify a single number</span><br>        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># -1表示自适应</span><br>        x = x.view(-<span class="hljs-number">1</span>, self.num_flat_features(x))<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">num_flat_features</span>(<span class="hljs-params">self, x</span>):<br>        size = x.size()[<span class="hljs-number">1</span>:]  <span class="hljs-comment"># all dimensions except the batch dimension</span><br>        num_features = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> size:<br>            num_features *= s<br>        <span class="hljs-keyword">return</span> num_features<br><br>net = Net()<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure>

<p>输出：</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231126173152038-20231126%2017:31:52.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231126173152038" style="zoom:50%;" />

<p>在模型中必须要定义 <code>forward</code> 函数，<code>backward</code> 函数（用来计算梯度）会被<code>autograd</code>自动创建。 可以在 <code>forward</code> 函数中使用任何针对 Tensor 的操作。</p>
<p><code>net.parameters()</code>返回可被学习的参数（权重）列表和值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> parameters <span class="hljs-keyword">in</span> net.parameters():<br>    <span class="hljs-built_in">print</span>(parameters)<br></code></pre></td></tr></table></figure>

<p>net.named_parameters可同时返回可学习的参数及名称。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> name,parameters <span class="hljs-keyword">in</span> net.named_parameters():<br>    <span class="hljs-built_in">print</span>(name,<span class="hljs-string">&#x27;:&#x27;</span>,parameters.size())<br></code></pre></td></tr></table></figure>



<p>测试随机输入32×32。 注：这个网络（LeNet）期望的输入大小是32×32，如果使用MNIST数据集来训练这个网络，请把图片大小重新调整到32×32。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>)<br>out = net(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(out)<br><span class="hljs-comment"># tensor([[ 0.1120,  0.0713,  0.1014, -0.0696, -0.1210,  0.0084, -0.0206,  0.1366,</span><br><span class="hljs-comment">#          -0.0455, -0.0036]], grad_fn=&lt;AddmmBackward&gt;)</span><br><br><span class="hljs-comment"># 将所有参数的梯度缓存清零，然后进行随机梯度的的反向传播：</span><br>net.zero_grad()<br>out.backward(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure>

<p><strong>回顾:</strong></p>
<ul>
<li><code>torch.Tensor</code>：一个用过自动调用 <code>backward()</code>实现支持自动梯度计算的 <em>多维数组</em> ， 并且保存关于这个向量的<em>梯度</em> w.r.t.</li>
<li><code>nn.Module</code>：神经网络模块。封装参数、移动到GPU上运行、导出、加载等。</li>
<li><code>nn.Parameter</code>：一种变量，当把它赋值给一个<code>Module</code>时，被 <em>自动</em> 地注册为一个参数。</li>
<li><code>autograd.Function</code>：实现一个自动求导操作的前向和反向定义，每个变量操作至少创建一个函数节点，每一个<code>Tensor</code>的操作都回创建一个接到创建<code>Tensor</code>和 <em>编码其历史</em> 的函数的<code>Function</code>节点。</li>
</ul>
<p><strong>重点如下：</strong></p>
<ul>
<li>定义一个网络</li>
<li>处理输入，调用backword</li>
</ul>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>一个损失函数接受一对 (output, target) 作为输入，计算一个值来估计网络的输出和目标值相差多少。</p>
<p>nn包中有很多不同的<a target="_blank" rel="noopener" href="https://pytorch.org/docs/nn.html#loss-functions">损失函数</a>。 <code>nn.MSELoss</code>是一个比较简单的损失函数，它计算输出和目标间的<strong>均方误差</strong>， 例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">output = net(<span class="hljs-built_in">input</span>)<br>target = torch.randn(<span class="hljs-number">10</span>)  <span class="hljs-comment"># 随机值作为样例</span><br>target = target.view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># 使target和output的shape相同</span><br>criterion = nn.MSELoss()<br><br>loss = criterion(output, target)<br><span class="hljs-built_in">print</span>(loss)<br><span class="hljs-comment"># tensor(0.8109, grad_fn=&lt;MseLossBackward&gt;)</span><br></code></pre></td></tr></table></figure>

<p>现在，如果在反向过程中跟随loss ， 使用它的 .grad_fn 属性，将看到如下所示的计算图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">input</span> -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d<br>      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear<br>      -&gt; MSELoss<br>      -&gt; loss<br></code></pre></td></tr></table></figure>

<p>所以，当我们调用 <code>loss.backward()</code>时,整张计算图都会 根据loss进行微分，而且图中所有设置为<code>requires_grad=True</code>的张量将会拥有一个随着梯度累积的<code>.grad</code> 张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(loss.grad_fn)  <span class="hljs-comment"># MSELoss</span><br><span class="hljs-built_in">print</span>(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  <span class="hljs-comment"># Linear</span><br><span class="hljs-built_in">print</span>(loss.grad_fn.next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].next_functions[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  <span class="hljs-comment"># ReLU</span><br></code></pre></td></tr></table></figure>

<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>调用loss.backward()获得反向传播的误差。</p>
<p>但是在调用前需要清除已存在的梯度，否则梯度将被累加到已存在的梯度。</p>
<p>现在，我们将调用loss.backward()，并查看conv1层的偏差（bias）项在反向传播前后的梯度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">net.zero_grad()     <span class="hljs-comment"># 清除梯度</span><br><br><span class="hljs-built_in">print</span>(net.conv1.bias.grad) <span class="hljs-comment"># tensor([0., 0., 0., 0., 0., 0.])</span><br><br>loss.backward()<br><br><span class="hljs-built_in">print</span>(net.conv1.bias.grad) <span class="hljs-comment"># tensor([ 0.0051,  0.0042,  0.0026,  0.0152, -0.0040, -0.0036])</span><br></code></pre></td></tr></table></figure>

<h3 id="更新权重（优化器optim）"><a href="#更新权重（优化器optim）" class="headerlink" title="更新权重（优化器optim）"></a>更新权重（优化器optim）</h3><p>在实践中最简单的权重更新规则是随机梯度下降（SGD）：</p>
<p>$weight &#x3D; weight - learning_rate * gradient$</p>
<p>我们可以使用简单的Python代码实现这个规则：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">learning_rate = <span class="hljs-number">0.01</span><br><span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> net.parameters():<br>    f.data.sub_(f.grad.data * learning_rate)<br></code></pre></td></tr></table></figure>

<p>但是当使用神经网络是想要使用各种不同的更新规则时，比如SGD、Nesterov-SGD、&#x3D;&#x3D;Adam&#x3D;&#x3D;、RMSPROP等，PyTorch中构建了一个包<code>torch.optim</code>实现了所有的这些规则。 使用它们非常简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># create your optimizer</span><br>optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.01</span>)<br><br><span class="hljs-comment"># in your training loop:</span><br>optimizer.zero_grad()   <span class="hljs-comment"># zero the gradient buffers</span><br>output = net(<span class="hljs-built_in">input</span>)<br>loss = criterion(output, target)<br>loss.backward()<br>optimizer.step()    <span class="hljs-comment"># Does the update</span><br></code></pre></td></tr></table></figure>

<p>Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 这里的lr，betas，还有eps都是用默认值即可，所以Adam是一个使用起来最简单的优化方法</span><br>optimizer = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-08</span>)<br></code></pre></td></tr></table></figure>



<h2 id="5-训练一个分类器"><a href="#5-训练一个分类器" class="headerlink" title="5 训练一个分类器"></a>5 训练一个分类器</h2><h3 id="关于数据"><a href="#关于数据" class="headerlink" title="关于数据"></a>关于数据</h3><p>一般情况下处理图像、文本、音频和视频数据时，可以使用标准的Python包来加载数据到一个numpy数组中。 然后把这个数组转换成 <code>torch.*Tensor</code>。</p>
<ul>
<li>图像可以使用 Pillow, OpenCV</li>
<li>音频可以使用 scipy, librosa</li>
<li>文本可以使用原始Python和Cython来加载，或者使用 NLTK或 SpaCy 处理</li>
</ul>
<h3 id="torchvision包"><a href="#torchvision包" class="headerlink" title="torchvision包"></a>torchvision包</h3><blockquote>
<p>torchvision 是PyTorch中专门用来处理图像的库，PyTorch官网的安装教程中最后的pip install torchvision 就是安装这个包。</p>
</blockquote>
<h4 id="torchvision-datasets"><a href="#torchvision-datasets" class="headerlink" title="torchvision.datasets"></a>torchvision.datasets</h4><p>特别的，对于图像任务，我们创建了一个包 <code>torchvision</code>，它包含了处理一些基本图像数据集的方法。这些数据集包括 Imagenet, CIFAR10, MNIST 等。除了数据加载以外，<code>torchvision</code> 还包含了图像转换器， <code>torchvision.datasets</code> 和 <code>torch.utils.data.DataLoader</code>。</p>
<p>可直接使用：</p>
<ul>
<li>MNIST</li>
<li>COCO</li>
<li>Captions</li>
<li>Detection</li>
<li>LSUN</li>
<li>ImageFolder</li>
<li>Imagenet-12</li>
<li>CIFAR</li>
<li>STL10</li>
<li>SVHN</li>
<li>PhotoTour</li>
</ul>
<p>使用示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision.datasets <span class="hljs-keyword">as</span> datasets<br>trainset = datasets.MNIST(root=<span class="hljs-string">&#x27;./data&#x27;</span>, <span class="hljs-comment"># 表示 MNIST 数据的加载的目录</span><br>                                      train=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># 表示是否加载数据库的训练集，false的时候加载测试集</span><br>                                      download=<span class="hljs-literal">True</span>, <span class="hljs-comment"># 表示是否自动下载 MNIST 数据集</span><br>                                      transform=<span class="hljs-literal">None</span>) <span class="hljs-comment"># 表示是否需要对数据进行预处理，none为不进行预处理</span><br></code></pre></td></tr></table></figure>

<p><code>torchvision</code>包不仅提供了巨大的便利，也避免了代码的重复。</p>
<h4 id="torchvision-models"><a href="#torchvision-models" class="headerlink" title="torchvision.models"></a>torchvision.models</h4><p>torchvision不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习 torchvision.models模块的 子模块中包含以下模型结构。</p>
<ul>
<li>AlexNet</li>
<li>VGG</li>
<li>ResNet</li>
<li>SqueezeNet</li>
<li>DenseNet</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#我们直接可以使用训练好的模型，当然这个与datasets相同，都是需要从服务器下载的</span><br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br>resnet18 = models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<h4 id="torchvision-transforms"><a href="#torchvision-transforms" class="headerlink" title="torchvision.transforms"></a>torchvision.transforms</h4><p>transforms 模块提供了一般的图像转换操作类，用作数据处理和数据增强</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms <span class="hljs-keyword">as</span> transforms<br>transform = transforms.Compose([<br>    transforms.RandomCrop(<span class="hljs-number">32</span>, padding=<span class="hljs-number">4</span>),  <span class="hljs-comment">#先四周填充0，在把图像随机裁剪成32*32</span><br>    transforms.RandomHorizontalFlip(),  <span class="hljs-comment">#图像一半的概率翻转，一半的概率不翻转</span><br>    transforms.RandomRotation((-<span class="hljs-number">45</span>,<span class="hljs-number">45</span>)), <span class="hljs-comment">#随机旋转</span><br>    transforms.ToTensor(),<br>    transforms.Normalize((<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.4822</span>, <span class="hljs-number">0.4465</span>), (<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>)), <span class="hljs-comment">#R,G,B每层的归一化用到的均值和方差</span><br>])<br><span class="hljs-comment"># 肯定有人会问：(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) 这几个数字是什么意思？</span><br><span class="hljs-comment"># 官方的这个帖子有详细的说明: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21 这些都是根据ImageNet训练的归一化参数，可以直接使用，我们认为这个是固定值就可以</span><br></code></pre></td></tr></table></figure>



<h3 id="训练一个图像分类器"><a href="#训练一个图像分类器" class="headerlink" title="训练一个图像分类器"></a>训练一个图像分类器</h3><p>在这个教程中，我们使用CIFAR10数据集，它有如下10个类别 ：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。CIFAR-10的图像都是 3x32x32大小的，即，3颜色通道，32x32像素。</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231126192752538-20231126%2019:27:52.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231126192752538" style="zoom:50%;" />

<p>依次按照下列顺序进行：</p>
<ol>
<li>使用<code>torchvision</code>加载和归一化CIFAR10训练集和测试集</li>
<li>定义一个卷积神经网络</li>
<li>定义损失函数</li>
<li>在训练集上训练网络</li>
<li>在测试集上测试网络</li>
</ol>
<h4 id="1-读取和归一化-CIFAR10"><a href="#1-读取和归一化-CIFAR10" class="headerlink" title="1 读取和归一化 CIFAR10"></a>1 读取和归一化 CIFAR10</h4><p>使用<code>torchvision</code>可以非常容易地加载CIFAR10。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br></code></pre></td></tr></table></figure>

<p>torchvision的输出是[0,1]的PILImage图像，我们把它转换为归一化范围为[-1, 1]的张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">transform = transforms.Compose(<br>    [transforms.ToTensor(),<br>     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br>trainset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>,<br>                                        download=<span class="hljs-literal">True</span>, transform=transform)<br>trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="hljs-number">4</span>,<br>                                          shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>)<br><br>testset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">False</span>,<br>                                       download=<span class="hljs-literal">True</span>, transform=transform)<br>testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="hljs-number">4</span>,<br>                                         shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">2</span>)<br><br>classes = (<span class="hljs-string">&#x27;plane&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>,<br>           <span class="hljs-string">&#x27;deer&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>展示一些训练图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 展示图像的函数</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">imshow</span>(<span class="hljs-params">img</span>):<br>    img = img / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>     <span class="hljs-comment"># unnormalize</span><br>    npimg = img.numpy()<br>    plt.imshow(np.transpose(npimg, (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)))<br><br><br><span class="hljs-comment"># 获取随机数据</span><br>dataiter = <span class="hljs-built_in">iter</span>(trainloader)<br>images, labels = dataiter.<span class="hljs-built_in">next</span>()<br><br><span class="hljs-comment"># 展示图像</span><br>imshow(torchvision.utils.make_grid(images))<br><span class="hljs-comment"># 显示图像标签</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">&#x27;%5s&#x27;</span> % classes[labels[j]] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231126194348498-20231126%2019:43:48.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231126194348498" style="zoom:50%;" />

<h4 id="2-定义一个卷积神经网络"><a href="#2-定义一个卷积神经网络" class="headerlink" title="2 定义一个卷积神经网络"></a>2 定义一个卷积神经网络</h4><p>从之前的神经网络一节复制神经网络代码，并修改为输入3通道图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        self.pool = nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.pool(F.relu(self.conv1(x)))<br>        x = self.pool(F.relu(self.conv2(x)))<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>)<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br>net = Net()<br></code></pre></td></tr></table></figure>

<h4 id="3-定义损失函数和优化器"><a href="#3-定义损失函数和优化器" class="headerlink" title="3 定义损失函数和优化器"></a>3 定义损失函数和优化器</h4><p>我们使用交叉熵作为损失函数，使用带动量的随机梯度下降。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>

<h4 id="4-训练网络"><a href="#4-训练网络" class="headerlink" title="4 训练网络"></a>4 训练网络</h4><p>我们只需在数据迭代器上循环，将数据输入给网络，并优化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):  <span class="hljs-comment"># 多批次循环</span><br><br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader, <span class="hljs-number">0</span>):<br>        <span class="hljs-comment"># 获取输入</span><br>        inputs, labels = data<br><br>        <span class="hljs-comment"># 梯度置0</span><br>        optimizer.zero_grad()<br><br>        <span class="hljs-comment"># 正向传播，反向传播，优化</span><br>        outputs = net(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-comment"># 打印状态信息</span><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">2000</span> == <span class="hljs-number">1999</span>:    <span class="hljs-comment"># 每2000批次打印一次</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> %<br>                  (epoch + <span class="hljs-number">1</span>, i + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">2000</span>))<br>            running_loss = <span class="hljs-number">0.0</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-在测试集上测试网络"><a href="#5-在测试集上测试网络" class="headerlink" title="5 在测试集上测试网络"></a>5 在测试集上测试网络</h4><p>我们在整个训练集上进行了2次训练，但是我们需要检查网络是否从数据集中学习到有用的东西。 通过预测神经网络输出的类别标签与实际情况标签进行对比来进行检测。 如果预测正确，我们把该样本添加到正确预测列表。 第一步，显示测试集中的图片并熟悉图片内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">dataiter = <span class="hljs-built_in">iter</span>(testloader)<br>images, labels = dataiter.<span class="hljs-built_in">next</span>()<br><br><span class="hljs-comment"># 显示图片</span><br>imshow(torchvision.utils.make_grid(images))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;GroundTruth: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">&#x27;%5s&#x27;</span> % classes[labels[j]] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231126195000861-20231126%2019:50:01.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231126195000861" style="zoom:50%;" />

<p>让我们看看神经网络认为以上图片是什么。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs = net(images)<br></code></pre></td></tr></table></figure>

<p>输出是10个标签的能量。 一个类别的能量越大，神经网络越认为它是这个类别。所以让我们得到最高能量的标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">_, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Predicted: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">&#x27;%5s&#x27;</span> % classes[predicted[j]]<br>                              <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br><br><span class="hljs-comment"># Predicted:  plane plane plane plane</span><br></code></pre></td></tr></table></figure>

<p>接下来让看看网络在整个测试集上的结果如何。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> testloader:<br>        images, labels = data<br>        outputs = net(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (<br>    <span class="hljs-number">100</span> * correct / total))<br><br><span class="hljs-comment"># Accuracy of the network on the 10000 test images: 9 %</span><br></code></pre></td></tr></table></figure>

<p>结果看起来不错，至少比随机选择要好，随机选择的正确率为10%。 似乎网络学习到了一些东西。</p>
<p>在识别哪一个类的时候好，哪一个不好呢？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">class_correct = <span class="hljs-built_in">list</span>(<span class="hljs-number">0.</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))<br>class_total = <span class="hljs-built_in">list</span>(<span class="hljs-number">0.</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> testloader:<br>        images, labels = data<br>        outputs = net(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br>        c = (predicted == labels).squeeze()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>            label = labels[i]<br>            class_correct[label] += c[i].item()<br>            class_total[label] += <span class="hljs-number">1</span><br><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy of %5s : %2d %%&#x27;</span> % (<br>        classes[i], <span class="hljs-number">100</span> * class_correct[i] / class_total[i]))<br></code></pre></td></tr></table></figure>

<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs matlab">Accuracy of plane : <span class="hljs-number">99</span> <span class="hljs-comment">%</span><br>Accuracy of   car :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of  bird :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of   <span class="hljs-built_in">cat</span> :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of  deer :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of   dog :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of  frog :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of horse :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of  ship :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br>Accuracy of truck :  <span class="hljs-number">0</span> <span class="hljs-comment">%</span><br></code></pre></td></tr></table></figure>

<h3 id="在GPU上训练"><a href="#在GPU上训练" class="headerlink" title="在GPU上训练"></a>在GPU上训练</h3><p>把一个神经网络移动到GPU上训练就像把一个Tensor转换GPU上一样简单。并且这个操作会递归遍历有所模块，并将其参数和缓冲区转换为CUDA张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-comment"># 确认我们的电脑支持CUDA，然后显示CUDA信息：</span><br><br><span class="hljs-built_in">print</span>(device)<br><br><span class="hljs-comment"># 递归遍历所有模块并将模块的参数和缓冲区 转换成CUDA张量</span><br>net.to(device)<br><span class="hljs-comment"># inputs, targets 和 images 也要转换</span><br>inputs, labels = inputs.to(device), labels.to(device)<br></code></pre></td></tr></table></figure>

<h2 id="6-数据并行"><a href="#6-数据并行" class="headerlink" title="6 数据并行"></a>6 数据并行</h2><p>PyTorch非常容易就可以使用多GPU，用如下方式把一个模型放到GPU上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span>)<br>model.to(device)<br></code></pre></td></tr></table></figure>

<p>GPU: 然后复制所有的张量到GPU上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mytensor = my_tensor.to(device)<br></code></pre></td></tr></table></figure>

<p>请注意，只调用<code>my_tensor.to(device)</code>并没有复制张量到GPU上，而是返回了一个copy。所以你需要把它赋值给一个新的张量并在GPU上使用这个张量。</p>
<p>在多GPU上执行前向和反向传播是自然而然的事。 但是PyTorch默认将只使用一个GPU。</p>
<p>使用<code>DataParallel</code>可以轻易的让模型并行运行在多个GPU上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model = nn.DataParallel(model)<br></code></pre></td></tr></table></figure>

<h3 id="导入和参数"><a href="#导入和参数" class="headerlink" title="导入和参数"></a>导入和参数</h3><p>导入PyTorch模块和定义参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><br><span class="hljs-comment"># Parameters and DataLoaders</span><br>input_size = <span class="hljs-number">5</span><br>output_size = <span class="hljs-number">2</span><br><br>batch_size = <span class="hljs-number">30</span><br>data_size = <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure>

<p>Device</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="虚拟数据集"><a href="#虚拟数据集" class="headerlink" title="虚拟数据集"></a>虚拟数据集</h3><p>制作一个虚拟（随机）数据集， 你只需实现 <code>__getitem__</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RandomDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, length</span>):<br>        self.<span class="hljs-built_in">len</span> = length<br>        self.data = torch.randn(length, size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> self.data[index]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.<span class="hljs-built_in">len</span><br><br>rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size),<br>                         batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<h3 id="简单模型"><a href="#简单模型" class="headerlink" title="简单模型"></a>简单模型</h3><p>作为演示，我们的模型只接受一个输入，执行一个线性操作，然后得到结果。 说明：<code>DataParallel</code>能在任何模型（CNN，RNN，Capsule Net等）上使用。</p>
<p>我们在模型内部放置了一条打印语句来打印输入和输出向量的大小。</p>
<p>请注意批次的秩为0时打印的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-comment"># Our model</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.fc = nn.Linear(input_size, output_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = self.fc(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\tIn Model: input size&quot;</span>, <span class="hljs-built_in">input</span>.size(),<br>              <span class="hljs-string">&quot;output size&quot;</span>, output.size())<br><br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure>

<h3 id="创建一个模型和数据并行"><a href="#创建一个模型和数据并行" class="headerlink" title="创建一个模型和数据并行"></a>创建一个模型和数据并行</h3><p>这是本教程的核心部分。</p>
<p>首先，我们需要创建一个模型实例和检测我们是否有多个GPU。 如果有多个GPU，使用<code>nn.DataParallel</code>来包装我们的模型。 然后通过<code>model.to(device)</code>把模型放到GPU上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">model = Model(input_size, output_size)<br><span class="hljs-keyword">if</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Let&#x27;s use&quot;</span>, torch.cuda.device_count(), <span class="hljs-string">&quot;GPUs!&quot;</span>)<br>    <span class="hljs-comment"># dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs</span><br>    model = nn.DataParallel(model)<br><br>model.to(device)<br></code></pre></td></tr></table></figure>

<h3 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h3><p>现在可以看到输入和输出张量的大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> rand_loader:<br>    <span class="hljs-built_in">input</span> = data.to(device)<br>    output = model(<span class="hljs-built_in">input</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Outside: input size&quot;</span>, <span class="hljs-built_in">input</span>.size(),<br>          <span class="hljs-string">&quot;output_size&quot;</span>, output.size())<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">In Model: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">5</span>]) output size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">2</span>])<br>Outside: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">5</span>]) output_size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">2</span>])<br>In Model: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">5</span>]) output size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">2</span>])<br>Outside: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">5</span>]) output_size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">2</span>])<br>In Model: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">5</span>]) output size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">2</span>])<br>Outside: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">5</span>]) output_size torch.Size([<span class="hljs-number">30</span>, <span class="hljs-number">2</span>])<br>In Model: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">10</span>, <span class="hljs-number">5</span>]) output size torch.Size([<span class="hljs-number">10</span>, <span class="hljs-number">2</span>])<br>Outside: <span class="hljs-built_in">input</span> size torch.Size([<span class="hljs-number">10</span>, <span class="hljs-number">5</span>]) output_size torch.Size([<span class="hljs-number">10</span>, <span class="hljs-number">2</span>])<br></code></pre></td></tr></table></figure>



<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>DataParallel会自动的划分数据，并将作业发送到多个GPU上的多个模型。 并在每个模型完成作业后，收集合并结果并返回。</p>
<p>更多信息请看这里： <a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html">https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html</a>.</p>
<h2 id="7-数学基础"><a href="#7-数学基础" class="headerlink" title="7 数学基础"></a>7 数学基础</h2><h3 id="监督学习和无监督学习"><a href="#监督学习和无监督学习" class="headerlink" title="监督学习和无监督学习"></a>监督学习和无监督学习</h3><p>监督学习、无监督学习、半监督学习、强化学习是我们日常接触到的常见的四个机器学习方法：</p>
<ul>
<li>监督学习：通过已有的训练样本（即已知数据以及其对应的输出）去训练得到一个最优模型（这个模型属于某个函数的集合，最优则表示在某个评价准则下是最佳的），再利用这个模型将所有的输入映射为相应的输出。</li>
<li>无监督学习：它与监督学习的不同之处，在于我们事先没有任何训练样本，而需要直接对数据进行建模。 </li>
<li>半监督学习 ：在训练阶段结合了大量未标记的数据和少量标签数据。与使用所有标签数据的模型相比，使用训练集的训练模型在训练时可以更为准确。</li>
<li>强化学习：我们设定一个回报函数（reward function），通过这个函数来确认否越来越接近目标，类似我们训练宠物，如果做对了就给他奖励，做错了就给予惩罚，最后来达到我们的训练目的。</li>
</ul>
<h3 id="损失函数-Loss-Function"><a href="#损失函数-Loss-Function" class="headerlink" title="损失函数(Loss Function)"></a>损失函数(Loss Function)</h3><p>损失函数（loss function）是用来估量模型的预测值(我们例子中的output)与真实值（例子中的y_train）的不一致程度，它是一个非负实值函数，损失函数越小，模型的鲁棒性就越好。 我们训练模型的过程，就是通过不断的迭代计算，使用梯度下降的优化算法，使得损失函数越来越小。损失函数越小就表示算法达到意义上的最优。</p>
<p>这里有一个重点：因为PyTorch是使用mini-batch来进行计算的，所以损失函数的计算出来的结果已经对mini-batch取了平均</p>
<p>常见（PyTorch内置）的损失函数有以下几个：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127195459570-20231127%2019:55:03.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127195459570"></p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><h4 id="梯度-1"><a href="#梯度-1" class="headerlink" title="梯度"></a>梯度</h4><p>在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。 例如函数f(x,y), 分别对x，y求偏导数，求得的梯度向量就是(∂f&#x2F;∂x, ∂f&#x2F;∂y)T，简称grad f(x,y)或者▽f(x,y)。</p>
<p>几何上讲，梯度就是函数变化增加最快的地方，沿着梯度向量的方向，更加容易找到函数的最大值。反过来说，沿着梯度向量相反的方向梯度减少最快，也就是更加容易找到函数的最小值。</p>
<p>我们需要最小化损失函数，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。</p>
<h4 id="梯度下降法直观解释"><a href="#梯度下降法直观解释" class="headerlink" title="梯度下降法直观解释"></a>梯度下降法直观解释</h4><p>梯度下降法就好比下山，我们并不知道下山的路，于是决定走一步算一步，每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。</p>
<p>如下图所示</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127200723735-20231127%2020:07:23.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127200723735" style="zoom:50%;" />

<p>这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处（局部最优解）。</p>
<p>这个问题在以前的机器学习中可能会遇到，因为机器学习中的特征比较少，所以导致很可能陷入到一个局部最优解中出不来，但是到了深度学习，动辄百万甚至上亿的特征，出现这种情况的概率几乎为0，所以我们可以不用考虑这个问题。</p>
<p><code>torch.optim</code>是一个实现了各种优化算法的库。大部分常用优化算法都有实现，我们直接调用即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127203235077-20231127%2020:32:35.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127203235077"></p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>在神经网络的计算过程中，每层都相当于矩阵相乘，无论神经网络有多少层输出都是输入的线性组合，就算我们有几千层的计算，无非还是个矩阵相乘，和一层矩阵相乘所获得的信息差距不大，所以需要激活函数来引入非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中，增加了神经网络模型泛化的特性。</p>
<p>早期研究神经网络主要采用sigmoid函数或者tanh函数，输出有界，很容易充当下一层的输入。 近些年Relu函数及其改进型（如Leaky-ReLU、P-ReLU、R-ReLU等），由于计算简单、效果好所以在多层神经网络中应用比较多。</p>
<p>下面来总结下较常见的激活函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 初始化一些信息</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>x= torch.linspace(-<span class="hljs-number">10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">60</span>)<br></code></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127203721206-20231127%2020:37:21.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127203721206"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127203757992-20231127%2020:37:58.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127203757992"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127203839040-20231127%2020:38:39.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127203839040"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127203905801-20231127%2020:39:05.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127203905801"></p>
<h2 id="8-卷积神经网络-CNN"><a href="#8-卷积神经网络-CNN" class="headerlink" title="8 卷积神经网络 CNN"></a>8 卷积神经网络 CNN</h2><p>卷积神经网络由一个或多个卷积层和顶端的全连通层（也可以使用1x1的卷积层作为最终的输出）组成一种前馈神经网络。一般的认为，卷积神经网络是由Yann LeCun大神在1989年提出的LeNet中首先被使用，但是由于当时的计算能力不够，并没有得到广泛的应用，到了1998年Yann LeCun及其合作者构建了更加完备的卷积神经网络LeNet-5并在手写数字的识别问题中取得成功，LeNet-5的成功使卷积神经网络的应用得到关注。LeNet-5沿用了LeCun (1989) 的学习策略并在原有设计中加入了池化层对输入特征进行筛选 。LeNet-5基本上定义了现代卷积神经网络的基本结构，其构筑中交替出现的卷积层-池化层被认为有效提取了输入图像的平移不变特征，使得对于特征的提取前进了一大步，所以我们一般的认为，Yann LeCun是卷积神经网络的创始人。</p>
<p>2006年后，随着深度学习理论的完善，尤其是计算能力的提升和参数微调（fine-tuning）等技术的出现，卷积神经网络开始快速发展，在结构上不断加深，各类学习和优化理论得到引入，2012年的AlexNet、2014年的VGGNet、GoogLeNet 和2015年的ResNet,使得卷积神经网络几乎成为了深度学习中图像处理方面的标配。</p>
<h3 id="为什么要使用卷积神经网络"><a href="#为什么要使用卷积神经网络" class="headerlink" title="为什么要使用卷积神经网络"></a>为什么要使用卷积神经网络</h3><p>对于计算机视觉来说，每一个图像是由一个个像素点构成，每个像素点有三个通道，分别代表RGB三种颜色(不计算透明度)，我们以手写识别的数据集MNIST举例，每个图像的是一个长宽均为28，channel为1的单色图像，如果使用全连接的网络结构，即，网络中的神经与相邻层上的每个神经元均连接，那就意味着我们的网络有28 * 28 &#x3D;784个神经元（RGB3色的话还要*3），hidden层如果使用了15个神经元，需要的参数个数(w和b)就有：28 * 28 * 15 * 10 + 15 + 10&#x3D;117625个，这个数量级到现在为止也是一个很恐怖的数量级，一次反向传播计算量都是巨大的，这还展示一个单色的28像素大小的图片，如果我们使用更大的像素，计算量可想而知。</p>
<h3 id="结构组成"><a href="#结构组成" class="headerlink" title="结构组成"></a>结构组成</h3><p>上面说到传统的网络需要大量的参数，但是这些参数是否重复了呢，例如，我们识别一个人，只要看到他的眼睛，鼻子，嘴，还有脸基本上就知道这个人是谁了，只是用这些局部的特征就能做做判断了，并不需要所有的特征。 另外一点就是我们上面说的可以有效提取了输入图像的平移不变特征，就好像我们看到了这是个眼睛，这个眼镜在左边还是在右边他都是眼睛，这就是平移不变性。 我们通过卷积的计算操作来提取图像局部的特征，每一层都会计算出一些局部特征，这些局部特征再汇总到下一层，这样一层一层的传递下去，特征由小变大，最后在通过这些局部的特征对图片进行处理，这样大大提高了计算效率，也提高了准确度。</p>
<h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p>在介绍卷积层之前要先介绍一下卷积的计算，这里使用<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/39022858">知乎</a>上的一张图片</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/9-20231127%2020:49:06.gif" srcset="/blog/img/loading.gif" lazyload alt="9"></p>
<p>我们会定义一个权重矩阵，也就是我们说的W（一般对于卷积来说，称作卷积的核kernel也有有人称做过滤器filter），这个权重矩阵的大小一般为<code>3 * 3</code> 或者<code>5 * 5</code>，但是在LeNet里面还用到了比较大的<code>7 * 7</code>，现在已经很少见了，因为根据经验的验证，3和5是最佳的大小。 我们以图上所示的方式，我们在输入矩阵上使用我们的权重矩阵进行滑动，每滑动一步，将所覆盖的值与矩阵对应的值相乘，并将结果求和并作为输出矩阵的一项，依次类推直到全部计算完成。</p>
<p>上图所示，我们输入是一个 <code>5 * 5</code>的矩阵，通过使用一次<code>3 * 3</code>的卷积核计算得到的计算结果是一个<code>3 * 3</code>的新矩阵。 那么新矩阵的大小是如何计算的呢？</p>
<p><strong>卷积核大小 f</strong></p>
<p>刚才已经说到了一个重要的参数，就是核的大小，我们这里用f来表示</p>
<p><strong>边界填充 (p)adding</strong></p>
<p>我们看到上图，经过计算后矩阵的大小改变了，如果要使矩阵大小不改变呢，我们可以先对矩阵做一个填充，将矩阵的周围全部再包围一层，这个矩阵就变成了<code>7*7</code>,上下左右各加1，相当于 <code>5+1+1=7</code> 这时，计算的结果还是 <code>5 * 5</code>的矩阵，保证了大小不变，这里的p&#x3D;1</p>
<p><strong>步长 (s)tride</strong></p>
<p>从动图上我们能够看到，每次滑动只是滑动了一个距离，如果每次滑动两个距离呢？那就需要使用步长这个参数。</p>
<p><strong>计算公式</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127205137085-20231127%2020:51:37.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127205137085"></p>
<p>n为我们输入的矩阵的大小，向下取整</p>
<p>这个公式非常重要一定要记住</p>
<p><strong>卷积层</strong></p>
<p>在每一个卷积层中我们都会设置多个核，每个核代表着不同的特征，这些特征就是我们需要传递到下一层的输出，而我们训练的过程就是训练这些不同的核。</p>
<h4 id="激活函数-1"><a href="#激活函数-1" class="headerlink" title="激活函数"></a>激活函数</h4><p>由于卷积的操作也是线性的，所以也需要进行激活，一般情况下，都会使用relu。</p>
<h4 id="池化层（pooling）"><a href="#池化层（pooling）" class="headerlink" title="池化层（pooling）"></a>池化层（pooling）</h4><p>池化层是CNN的重要组成部分，通过减少卷积层之间的连接，降低运算复杂程度，池化层的操作很简单，就想相当于是合并，我们输入一个过滤器的大小，与卷积的操作一样，也是一步一步滑动，但是过滤器覆盖的区域进行合并，只保留一个值。 合并的方式也有很多种，例如我们常用的两种取最大值maxpooling，取平均值avgpooling</p>
<p>池化层的输出大小公式也与卷积层一样，由于没有进行填充，所以p&#x3D;0，可以简化为$( 𝑛−𝑓)&#x2F;𝑠+1$</p>
<h4 id="dropout层"><a href="#dropout层" class="headerlink" title="dropout层"></a>dropout层</h4><p>dropout是2014年 Hinton 提出防止过拟合而采用的trick，增强了模型的泛化能力 Dropout（随机失活）是指在深度学习网络的训练过程中，按照一定的概率将一部分神经网络单元暂时从网络中丢弃，相当于从原始的网络中找到一个更瘦的网络，说的通俗一点，就是随机将一部分网络的传播掐断，听起来好像不靠谱，但是通过实际测试效果非常好。 有兴趣的可以去看一下原文<a target="_blank" rel="noopener" href="http://jmlr.org/papers/v15/srivastava14a.html">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a>这里就不详细介绍了。</p>
<h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>全链接层一般是作为最后的输出层使用，卷积的作用是提取图像的特征，最后的全连接层就是要通过这些特征来进行计算，输出我们所要的结果了，无论是分类，还是回归。</p>
<p>我们的特征都是使用矩阵表示的，所以再传入全连接层之前还需要对特征进行压扁，将他这些特征变成一维的向量，如果要进行分类的话，就是用sofmax作为输出，如果要是回归的话就直接使用linear即可。</p>
<blockquote>
<p>以上就是卷积神经网络几个主要的组成部分</p>
</blockquote>
<h3 id="经典模型"><a href="#经典模型" class="headerlink" title="经典模型"></a>经典模型</h3><h4 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h4><p>1998， Yann LeCun 的 LeNet5 <a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/lenet/index.html">官网</a></p>
<p>卷积神经网路的开山之作，麻雀虽小，但五脏俱全，卷积层、pooling层、全连接层，这些都是现代CNN网络的基本组件</p>
<ul>
<li>用卷积提取空间特征；</li>
<li>由空间平均得到子样本；</li>
<li>用 tanh 或 sigmoid 得到非线性；</li>
<li>用 multi-layer neural network（MLP）作为最终分类器；</li>
<li>层层之间用稀疏的连接矩阵，以避免大的计算成本。</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127205739614-20231127%2020:57:39.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127205739614" style="zoom:50%;" />

<p>输入：图像Size为32<em>32。这要比mnist数据库中最大的字母(28</em>28)还大。这样做的目的是希望潜在的明显特征，如笔画断续、角点能够出现在最高层特征监测子感受野的中心。</p>
<p>输出：10个类别，分别为0-9数字的概率</p>
<ol>
<li>C1层是一个卷积层，有6个卷积核（提取6种局部特征），核大小为5 * 5</li>
<li>S2层是pooling层，下采样（区域:2 * 2 ）降低网络训练参数及模型的过拟合程度。</li>
<li>C3层是第二个卷积层，使用16个卷积核，核大小:5 * 5 提取特征</li>
<li>S4层也是一个pooling层，区域:2*2</li>
<li>C5层是最后一个卷积层，卷积核大小:5 * 5 卷积核种类:120</li>
<li>最后使用全连接层，将C5的120个特征进行分类，最后输出0-9的概率</li>
</ol>
<p>以下代码来自<a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html">官方教程</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LeNet5</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(LeNet5, self).__init__()<br>        <span class="hljs-comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span><br>        <span class="hljs-comment"># kernel</span><br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-comment"># an affine operation: y = Wx + b</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>) <span class="hljs-comment"># 这里论文上写的是conv,官方教程用了线性层</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># Max pooling over a (2, 2) window</span><br>        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>        <span class="hljs-comment"># If the size is a square you can only specify a single number</span><br>        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="hljs-number">2</span>)<br>        x = x.view(-<span class="hljs-number">1</span>, self.num_flat_features(x))<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">num_flat_features</span>(<span class="hljs-params">self, x</span>):<br>        size = x.size()[<span class="hljs-number">1</span>:]  <span class="hljs-comment"># all dimensions except the batch dimension</span><br>        num_features = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> size:<br>            num_features *= s<br>        <span class="hljs-keyword">return</span> num_features<br><br><br>net = LeNet5()<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127205925464-20231127%2020:59:25.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127205925464" style="zoom:50%;" />

<h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h4><p>2012，Alex Krizhevsky 可以算作LeNet的一个更深和更广的版本，可以用来学习更复杂的对象 <a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">论文</a></p>
<ul>
<li>用rectified linear units（ReLU）得到非线性；</li>
<li>使用 dropout 技巧在训练期间有选择性地忽略单个神经元，来减缓模型的过拟合；</li>
<li>重叠最大池，避免平均池的平均效果；</li>
<li>使用 GPU NVIDIA GTX 580 可以减少训练时间，这比用CPU处理快了 10 倍，所以可以被用于更大的数据集和图像上。</li>
</ul>
<img src="/Users/azure/Library/Application Support/typora-user-images/image-20231127210020951.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127210020951" style="zoom:50%;" />

<ul>
<li>虽然 AlexNet只有8层，但是它有60M以上的参数总量，Alexnet有一个特殊的计算层，LRN层，做的事是对当前层的输出结果做平滑处理，这里就不做详细介绍了， Alexnet的每一阶段（含一次卷积主要计算的算作一层）可以分为8层：</li>
</ul>
<ol>
<li>con - relu - pooling - LRN ： 要注意的是input层是227*227，而不是paper里面的224，这里可以算一下，主要是227可以整除后面的conv1计算，224不整除。如果一定要用224可以通过自动补边实现，不过在input就补边感觉没有意义，补得也是0，这就是我们上面说的公式的重要性。</li>
<li>conv - relu - pool - LRN ： group&#x3D;2，这个属性强行把前面结果的feature map分开，卷积部分分成两部分做</li>
<li>conv - relu</li>
<li>conv - relu</li>
<li>conv - relu - pool</li>
<li>fc - relu - dropout ： dropout层，在alexnet中是说在训练的以1&#x2F;2概率使得隐藏层的某些neuron的输出为0，这样就丢到了一半节点的输出，BP的时候也不更新这些节点，防止过拟合。</li>
<li>fc - relu - dropout </li>
<li>fc - softmax</li>
</ol>
<p>在Pytorch的vision包中是包含Alexnet的官方实现的，我们直接使用官方版本看下网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br>model = torchvision.models.alexnet(pretrained=<span class="hljs-literal">False</span>) <span class="hljs-comment">#我们不下载预训练权重</span><br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127210332167-20231127%2021:03:32.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127210332167" style="zoom:50%;" />

<h4 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h4><p>2015，牛津的 VGG。<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.1556.pdf">论文</a></p>
<ul>
<li>每个卷积层中使用更小的 3×3 filters，并将它们组合成卷积序列</li>
<li>多个3×3卷积序列可以模拟更大的接收场的效果</li>
<li>每次的图像像素缩小一倍，卷积核的数量增加一倍</li>
</ul>
<p>VGG有很多个版本，也算是比较稳定和经典的model。它的特点也是连续conv多计算量巨大，这里我们以VGG16为例。</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127210426105-20231127%2021:04:26.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127210426105" style="zoom:50%;" />

<p>VGG清一色用小卷积核，结合作者和自己的观点，这里整理出小卷积核比用大卷积核的优势：</p>
<p>根据作者的观点，input8 -&gt; 3层conv3x3后，output&#x3D;2，等同于1层conv7x7的结果； input&#x3D;8 -&gt; 2层conv3x3后，output&#x3D;2，等同于2层conv5x5的结果</p>
<p>卷积层的参数减少。相比5x5、7x7和11x11的大卷积核，3x3明显地减少了参数量</p>
<p>通过卷积和池化层后，图像的分辨率降低为原来的一半，但是图像的特征增加一倍，这是一个十分规整的操作: 分辨率由输入的224-&gt;112-&gt;56-&gt;28-&gt;14-&gt;7， 特征从原始的RGB3个通道-&gt; 64 -&gt;128 -&gt; 256 -&gt; 512</p>
<p>这为后面的网络提供了一个标准，我们依旧使用Pytorch官方实现版本来查看</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br>model = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>) <span class="hljs-comment">#我们不下载预训练权重</span><br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127210605365-20231127%2021:06:05.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127210605365" style="zoom:50%;" />

<h4 id="GoogLeNet-Inception"><a href="#GoogLeNet-Inception" class="headerlink" title="GoogLeNet (Inception)"></a>GoogLeNet (Inception)</h4><p>2014，Google Christian Szegedy <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.00567">论文</a></p>
<ul>
<li>使用1×1卷积块（NiN）来减少特征数量，这通常被称为“瓶颈”，可以减少深层神经网络的计算负担。</li>
<li>每个池化层之前，增加 feature maps，增加每一层的宽度来增多特征的组合性</li>
</ul>
<p>googlenet最大的特点就是包含若干个inception模块，所以有时候也称作 inception net。 googlenet虽然层数要比VGG多很多，但是由于inception的设计，计算速度方面要快很多。</p>
<p>Inception架构的主要思想是找出如何让已有的稠密组件接近与覆盖卷积视觉网络中的最佳局部稀疏结构。现在需要找出最优的局部构造，并且重复几次。之前的一篇文献提出一个层与层的结构，在最后一层进行相关性统计，将高相关性的聚集到一起。这些聚类构成下一层的单元，且与上一层单元连接。假设前面层的每个单元对应于输入图像的某些区域，这些单元被分为滤波器组。在接近输入层的低层中，相关单元集中在某些局部区域，最终得到在单个区域中的大量聚类，在最后一层通过1x1的卷积覆盖。</p>
<p>上面的话听起来很生硬，其实解释起来很简单：每一模块我们都是用若干个不同的特征提取方式，例如 3x3卷积，5x5卷积，1x1的卷积，pooling等，都计算一下，最后再把这些结果通过Filter Concat来进行连接，找到这里面作用最大的。而网络里面包含了许多这样的模块，这样不用我们人为去判断哪个特征提取方式好，网络会自己解决（是不是有点像AUTO ML），在Pytorch中实现了InceptionA-E，还有InceptionAUX 模块。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># inception_v3需要scipy，所以没有安装的话pip install scipy 一下</span><br><span class="hljs-keyword">import</span> torchvision<br>model = torchvision.models.inception_v3(pretrained=<span class="hljs-literal">False</span>) <span class="hljs-comment">#我们不下载预训练权重</span><br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure>

<h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>2015，Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385">论文</a> Kaiming He 何凯明（音译）这个大神大家一定要记住，现在很多论文都有他参与(mask rcnn, focal loss)，Jian Sun孙剑老师就不用说了，现在旷视科技的首席科学家。 刚才的GoogLeNet已经很深了，ResNet可以做到更深，通过残差计算，可以训练超过1000层的网络，俗称跳连接</p>
<p><strong>退化问题</strong></p>
<p>网络层数增加，但是在训练集上的准确率却饱和甚至下降了。这个不能解释为overfitting，因为overfit应该表现为在训练集上表现更好才对。这个就是网络退化的问题，退化问题说明了深度网络不能很简单地被很好地优化</p>
<p><strong>残差网络的解决办法</strong></p>
<p>深层网络的后面那些层是恒等映射，那么模型就退化为一个浅层网络。那现在要解决的就是学习恒等映射函数了。让一些层去拟合一个潜在的恒等映射函数H(x) &#x3D; x，比较困难。如果把网络设计为H(x) &#x3D; F(x) + x。我们可以转换为学习一个残差函数F(x) &#x3D; H(x) - x。 只要F(x)&#x3D;0，就构成了一个恒等映射H(x) &#x3D; x. 而且，拟合残差肯定更加容易。</p>
<p>以上又很不好理解，继续解释下，先看图：</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127210928788-20231127%2021:09:29.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127210928788" style="zoom:50%;" />

<p>我们在激活函数前将上一层（或几层）的输出与本层计算的输出相加，将求和的结果输入到激活函数中做为本层的输出，引入残差后的映射对输出的变化更敏感，其实就是看本层相对前几层是否有大的变化，相当于是一个差分放大器的作用。图中的曲线就是残差中的shoutcut，他将前一层的结果直接连接到了本层，也就是俗称的跳连接。</p>
<p>我们以经典的resnet18来看一下网络结构</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127211013423-20231127%2021:10:13.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127211013423" style="zoom:50%;" />

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br>model = torchvision.models.resnet18(pretrained=<span class="hljs-literal">False</span>) <span class="hljs-comment">#我们不下载预训练权重</span><br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure>

<h3 id="如何选择网络"><a href="#如何选择网络" class="headerlink" title="如何选择网络"></a>如何选择网络</h3><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127211113811-20231127%2021:11:14.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127211113811" style="zoom:50%;" />

<p>以上表格可以清楚的看到准确率和计算量之间的对比。小型图片分类任务，resnet18基本上已经可以了，如果真对准确度要求比较高，再选其他更好的网络架构。</p>
<h2 id="9-循环神经网络-RNN"><a href="#9-循环神经网络-RNN" class="headerlink" title="9 循环神经网络 RNN"></a>9 循环神经网络 RNN</h2><p>我们的大脑区别于机器的一个最大的特征就是我们有记忆，并且能够根据自己的记忆对未知的事务进行推导，我们的思想拥有持久性的。但是本教程目前所介绍的神经网络结构各个元素之间是相互独立的，输入与输出是独立的。</p>
<h3 id="RNN的起因"><a href="#RNN的起因" class="headerlink" title="RNN的起因"></a>RNN的起因</h3><p>现实世界中，很多元素都是相互连接的，比如室外的温度是随着气候的变化而周期性的变化的、我们的语言也需要通过上下文的关系来确认所表达的含义。但是机器要做到这一步就相当得难了。因此，就有了现在的循环神经网络，他的本质是：拥有记忆的能力，并且会根据这些记忆的内容来进行推断。因此，他的输出就依赖于当前的输入和记忆。</p>
<h3 id="为什么需要RNN"><a href="#为什么需要RNN" class="headerlink" title="为什么需要RNN"></a>为什么需要RNN</h3><p>RNN背后的想法是利用顺序的信息。 在传统的神经网络中，我们假设所有输入（和输出）彼此独立。 如果你想预测句子中的下一个单词，你就要知道它前面有哪些单词，甚至要看到后面的单词才能够给出正确的答案。 RNN之所以称为循环，就是因为它们对序列的每个元素都会执行相同的任务，所有的输出都取决于先前的计算。 从另一个角度讲RNN的它是有“记忆”的，可以捕获到目前为止计算的信息。 理论上，RNN可以在任意长的序列中使用信息，但实际上它们仅限于回顾几个步骤。 循环神经网络的提出便是基于记忆模型的想法，期望网络能够记住前面出现的特征。并依据特征推断后面的结果，而且整体的网络结构不断循环，因为得名循环神经网络。</p>
<h3 id="RNN都能做什么"><a href="#RNN都能做什么" class="headerlink" title="RNN都能做什么"></a>RNN都能做什么</h3><p>RNN在许多NLP任务中取得了巨大成功。 在这一点上，我应该提到最常用的RNN类型是LSTM，它在捕获长期依赖性方面要比RNN好得多。 但不要担心，LSTM与我们将在本教程中开发的RNN基本相同，它们只是采用不同的方式来计算隐藏状态。 我们将在后面更详细地介绍LSTM。 以下是RNN在NLP中的一些示例： <strong>语言建模与生成文本</strong></p>
<p>我们通过语言的建模，可以通过给定的单词生成人类可以理解的以假乱真的文本</p>
<p><strong>机器翻译</strong></p>
<p>机器翻译类似于语言建模，我们的输入源语言中的一系列单词，通过模型的计算可以输出目标语言与之对应的内容。 </p>
<p><strong>语音识别</strong></p>
<p>给定来自声波的声学信号的输入序列，我们可以预测一系列语音片段及其概率，并把语音转化成文字</p>
<p><strong>生成图像描述</strong></p>
<p>与卷积神经网络一起，RNN可以生成未标记图像的描述。</p>
<h3 id="RNN的网络结构及原理"><a href="#RNN的网络结构及原理" class="headerlink" title="RNN的网络结构及原理"></a>RNN的网络结构及原理</h3><p>循环神经网络的基本结构特别简单，就是将网络的输出保存在一个记忆单元中，这个记忆单元和下一次的输入一起进入神经网络中。我们可以看到网络在输入的时候会联合记忆单元一起作为输入，网络不仅输出结果，还会将结果保存到记忆单元中，下图就是一个最简单的循环神经网络在输入时的结构示意图。</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127212511519-20231127%2021:25:11.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127212511519" style="zoom:50%;" />

<p>RNN 可以被看做是同一神经网络的多次赋值，每个神经网络模块会把消息传递给下一个，我们将这个图的结构展开。</p>
<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231127212545158-20231127%2021:25:45.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231127212545158" style="zoom:50%;" />

<p>网络中具有循环结构，这也是循环神经网络名字的由来，同时根据循环神经网络的结构也可以看出它在处理序列类型的数据上具有天然的优势。因为网络本身就是 一个序列结构，这也是所有循环神经网络最本质的结构。</p>
<p>循环神经网络具有特别好的记忆特性，能够将记忆内容应用到当前情景下，但是网络的记忆能力并没有想象的那么有效。记忆最大的问题在于它有遗忘性，我们总是更加清楚地记得最近发生的事情而遗忘很久之前发生的事情，循环神经网络同样有这样的问题。</p>
<p>pytorch 中使用 nn.RNN 类来搭建基于序列的循环神经网络，它的构造函数有以下几个参数：</p>
<ul>
<li>input_size：输入数据X的特征值的数目。 </li>
<li>hidden_size：隐藏层的神经元数量，也就是隐藏层的特征数量。</li>
<li>num_layers：循环神经网络的层数，默认值是 1。 </li>
<li>bias：默认为 True，如果为 false 则表示神经元不使用 bias 偏移参数。</li>
<li>batch_first：如果设置为 True，则输入数据的维度中第一个维度就是 batch 值，默认为 False。默认情况下第一个维度是序列的长度， 第二个维度才是 - - batch，第三个维度是特征数目。</li>
<li>dropout：如果不为空，则表示最后跟一个 dropout 层抛弃部分数据，抛弃数据的比例由该参数指定。</li>
</ul>
<p>RNN 中最主要的参数是 input_size 和 hidden_size，这两个参数务必要搞清楚。其余的参数通常不用设置，采用默认值就可以了。</p>
<p> 下面我们开始手动实现我们的RNN：参考的是karpathy大佬的文章：<a target="_blank" rel="noopener" href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">https://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,input_size,hidden_size</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 因为最后的操作是相加 所以hidden要和output的shape一致</span><br>        self.W_xh = torch.nn.Linear(input_size, hidden_size) <br>        self.W_hh = torch.nn.Linear(hidden_size, hidden_size)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, x, hidden</span>):<br>        <span class="hljs-keyword">return</span> self.step(x, hidden)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">step</span>(<span class="hljs-params">self, x, hidden</span>):<br>        <span class="hljs-comment">#前向传播的一步</span><br>        h1 = self.W_hh(hidden)<br>        w1 = self.W_xh(x)<br>        out = torch.tanh(h1 + w1)<br>        hidden = self.W_hh.weight<br>        <span class="hljs-keyword">return</span> out, hidden<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">rnn = RNN(<span class="hljs-number">20</span>, <span class="hljs-number">50</span>)<br><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">32</span> , <span class="hljs-number">20</span>)<br>h_0 = torch.randn(<span class="hljs-number">32</span>, <span class="hljs-number">50</span>) <br>seq_len = <span class="hljs-built_in">input</span>.shape[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(seq_len):<br>    output, hn = rnn(<span class="hljs-built_in">input</span>[i, :], h_0)<br><span class="hljs-built_in">print</span>(output.size(), h_0.size())<br></code></pre></td></tr></table></figure>

<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>LSTM 是 Long Short Term Memory Networks 的缩写，按字面翻译就是长的短时记忆网络。LSTM 的网络结构是 1997 年由 Hochreiter 和 Schmidhuber 提出的，随后这种网络结构变得非常流行。 LSTM虽然只解决了短期依赖的问题，并且它通过刻意的设计来避免长期依赖问题，这样的做法在实际应用中被证明还是十分有效的，有很多人跟进相关的工作解决了很多实际的问题，所以现在LSTM 仍然被广泛地使用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/lstm-20231127%2021:29:10.gif" srcset="/blog/img/loading.gif" lazyload alt="lstm"></p>
<p>标准的循环神经网络内部只有一个简单的层结构，而 LSTM 内部有 4 个层结构：</p>
<p>第一层是个忘记层：决定状态中丢弃什么信息</p>
<p>第二层tanh层用来产生更新值的候选项，说明状态在某些维度上需要加强，在某些维度上需要减弱</p>
<p>第三层sigmoid层（输入门层），它的输出值要乘到tanh层的输出上，起到一个缩放的作用，极端情况下sigmoid输出0说明相应维度上的状态不需要更新</p>
<p>最后一层决定输出什么，输出值跟状态有关。候选项中的哪些部分最终会被输出由一个sigmoid层来决定。</p>
<p>pytorch 中使用 nn.LSTM 类来搭建基于序列的循环神经网络，他的参数基本与RNN类似，这里就不列出了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">lstm = torch.nn.LSTM(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>,<span class="hljs-number">2</span>)<br><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>)<br>h0 = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">20</span>)<br>c0 = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">20</span>)<br>output, hn = lstm(<span class="hljs-built_in">input</span>, (h0, c0))<br><span class="hljs-built_in">print</span>(output.size(), hn[<span class="hljs-number">0</span>].size(), hn[<span class="hljs-number">1</span>].size())<br></code></pre></td></tr></table></figure>

<h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>GRU 是 gated recurrent units 的缩写，由 Cho在 2014 年提出。GRU 和 LSTM 最大的不同在于 GRU 将遗忘门和输入门合成了一个”更新门”，同时网络不再额外给出记忆状态，而是将输出结果作为记忆状态不断向后循环传递，网络的输人和输出都变得特别简单。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/gru-20231127%2021:30:02.gif" srcset="/blog/img/loading.gif" lazyload alt="gru"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">rnn = torch.nn.GRU(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>)<br>h_0= torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">20</span>)<br>output, hn = rnn(<span class="hljs-built_in">input</span>, h0)<br><span class="hljs-built_in">print</span>(output.size(),hn.size())<br></code></pre></td></tr></table></figure>



<h3 id="循环网络的向后传播（BPTT）"><a href="#循环网络的向后传播（BPTT）" class="headerlink" title="循环网络的向后传播（BPTT）"></a>循环网络的向后传播（BPTT）</h3><p>在向前传播的情况下，RNN的输入随着每一个时间步前进。在反向传播的情况下，我们“回到过去”改变权重，因此我们叫它通过时间的反向传播（BPTT）。</p>
<p>我们通常把整个序列（单词）看作一个训练样本，所以总的误差是每个时间步（字符）中误差的和。权重在每一个时间步长是相同的（所以可以计算总误差后一起更新）。</p>
<ol>
<li>使用预测输出和实际输出计算交叉熵误差</li>
<li>网络按照时间步完全展开</li>
<li>对于展开的网络，对于每一个实践步计算权重的梯度</li>
<li>因为对于所有时间步来说，权重都一样，所以对于所有的时间步，可以一起得到梯度（而不是像神经网络一样对不同的隐藏层得到不同的梯度）</li>
<li>随后对循环神经元的权重进行升级</li>
</ol>
<p>RNN展开的网络看起来像一个普通的神经网络。反向传播也类似于普通的神经网络，只不过我们一次得到所有时间步的梯度。如果有100个时间步，那么网络展开后将变得非常巨大，所以为了解决这个问题才会出现LSTM和GRU这样的结构。</p>
<p>循环神经网络目前在自然语言处理中应用最为火热，所以后面的内容将介绍一下循环神经网络在处理NLP的时候需要用到的一些其他的知识</p>
<h3 id="词嵌入（word-embedding）"><a href="#词嵌入（word-embedding）" class="headerlink" title="词嵌入（word embedding）"></a>词嵌入（word embedding）</h3><p>在我们人类交流过程中表征词汇是直接使用英文单词来进行表征的，但是对于计算机来说，是无法直接认识单词的。为了让计算机能够能更好地理解我们的语言，建立更好的语言模型，我们需要将词汇进行表征。</p>
<p>在图像分类问题会使用 one-hot 编码。比如LeNet中一共有10个数字0-9，如果这个数字是2的话类，它的编码就是 (0，0，1，0， 0，0 ，0，0，0，0)，对于分类问题这样表示十分的清楚，但是在自然语言处理中，因为单词的数目过多比如有 10000 个不同的词，那么使用 one-hot 这样的方式来定义，效率就特别低，每个单词都是 10000 维的向量。其中只有一位是 1 ， 其余都是 0，特别占用内存，而且也不能体现单词的词性，因为每一个单词都是 one-hot，虽然有些单词在语义上会更加接近.但是 one-hot 没办法体现这个特点，所以 必须使用另外一种方式定义每一个单词。</p>
<p>用不同的特征来对各个词汇进行表征，相对与不同的特征，不同的单词均有不同的值这就是词嵌入。</p>
<p>词嵌入不仅对不同单词实现了特征化的表示，还能通过计算词与词之间的相似度，实际上是在多维空间中，寻找词向量之间各个维度的距离相似度，我们就可以实现类比推理，比如说夏天和热，冬天和冷，都是有关联关系的。</p>
<p>在 PyTorch 中我们用 nn.Embedding 层来做嵌入词袋模型，Embedding层第一个输入表示我们有多少个词，第二个输入表示每一个词使用多少维度的向量表示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># an Embedding module containing 10 tensors of size 3</span><br>embedding = torch.nn.Embedding(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>)<br><span class="hljs-comment"># a batch of 2 samples of 4 indices each</span><br><span class="hljs-built_in">input</span> = torch.LongTensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">9</span>]])<br>output = embedding(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(output.size())<br></code></pre></td></tr></table></figure>

<h3 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h3><p>在生成第一个词的分布后，可以使用贪心搜索会根据我们的条件语言模型挑选出最有可能输出的第一个词语，但是对于贪心搜索算法来说，我们的单词库中有成百到千万的词汇，去计算每一种单词的组合的可能性是不可行的。所以我们使用近似的搜索办法，使得条件概率最大化或者近似最大化的句子，而不是通过单词去实现。</p>
<p>Beam Search（集束搜索）是一种启发式图搜索算法，通常用在图的解空间比较大的情况下，为了减少搜索所占用的空间和时间，在每一步深度扩展的时候，剪掉一些质量比较差的结点，保留下一些质量较高的结点。虽然Beam Search算法是不完全的，但是用于了解空间较大的系统中，可以减少空间占用和时间。</p>
<p>Beam search可以看做是做了约束优化的广度优先搜索，首先使用广度优先策略建立搜索树，树的每层，按照启发代价对节点进行排序，然后仅留下预先确定的个数（Beam width-集束宽度）的节点，仅这些节点在下一层次继续扩展，其他节点被剪切掉。</p>
<ol>
<li>将初始节点插入到list中</li>
<li>将给节点出堆，如果该节点是目标节点，则算法结束；</li>
<li>否则扩展该节点，取集束宽度的节点入堆。然后到第二步继续循环。</li>
<li>算法结束的条件是找到最优解或者堆为空。</li>
</ol>
<p>在使用上，集束宽度可以是预先约定的，也可以是变化的，具体可以根据实际场景调整设定。</p>
<h2 id="10-MNIST数据集手写数字识别"><a href="#10-MNIST数据集手写数字识别" class="headerlink" title="10 MNIST数据集手写数字识别"></a>10 MNIST数据集手写数字识别</h2><h3 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h3><p>MNIST 包括6万张28x28的训练样本，1万张测试样本，很多教程都会对它”下手”几乎成为一个 “典范”，可以说它就是计算机视觉里面的Hello World。所以我们这里也会使用MNIST来进行实战。</p>
<p>前面在介绍卷积神经网络的时候说到过LeNet-5，LeNet-5之所以强大就是因为在当时的环境下将MNIST数据的识别率提高到了99%，这里我们也自己从头搭建一个卷积神经网络，也达到99%的准确率。</p>
<p>首先，我们定义一些超参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">BATCH_SIZE=<span class="hljs-number">512</span> <span class="hljs-comment">#大概需要2G的显存</span><br>EPOCHS=<span class="hljs-number">20</span> <span class="hljs-comment"># 总共训练批次</span><br>DEVICE = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>) <span class="hljs-comment"># 让torch判断是否使用GPU，建议使用GPU环境，因为会快很多</span><br></code></pre></td></tr></table></figure>

<p>因为Pytorch里面包含了MNIST的数据集，所以我们这里直接使用即可。 如果第一次执行会生成data文件夹，并且需要一些时间下载，如果以前下载过就不会再次下载了</p>
<h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p>由于官方已经实现了dataset，所以这里可以直接使用DataLoader来对数据进行读取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">train_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">&#x27;data&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, <br>                       transform=transforms.Compose([<br>                           transforms.ToTensor(),<br>                           transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                       ])),<br>        batch_size=BATCH_SIZE, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">test_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">&#x27;data&#x27;</span>, train=<span class="hljs-literal">False</span>, transform=transforms.Compose([<br>                           transforms.ToTensor(),<br>                           transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                       ])),<br>        batch_size=BATCH_SIZE, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<h3 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h3><p>下面我们定义一个网络，网络包含两个卷积层，conv1和conv2，然后紧接着两个线性层作为输出，最后输出10个维度，这10个维度我们作为0-9的标识来确定识别出的是那个数字</p>
<p>在这里建议大家将每一层的输入和输出维度都作为注释标注出来，这样后面阅读代码的会方便很多</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ConvNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># batch*1*28*28（每次会送入batch个样本，输入通道数1（黑白图像），图像分辨率是28x28）</span><br>        <span class="hljs-comment"># 下面的卷积层Conv2d的第一个参数指输入通道数，第二个参数指输出通道数，第三个参数指卷积核的大小</span><br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">5</span>) <span class="hljs-comment"># 输入通道数1，输出通道数10，核的大小5</span><br>        self.conv2 = nn.Conv2d(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">3</span>) <span class="hljs-comment"># 输入通道数10，输出通道数20，核的大小3</span><br>        <span class="hljs-comment"># 下面的全连接层Linear的第一个参数指输入通道数，第二个参数指输出通道数</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">20</span>*<span class="hljs-number">10</span>*<span class="hljs-number">10</span>, <span class="hljs-number">500</span>) <span class="hljs-comment"># 输入通道数是2000，输出通道数是500</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">10</span>) <span class="hljs-comment"># 输入通道数是500，输出通道数是10，即10分类</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        in_size = x.size(<span class="hljs-number">0</span>) <span class="hljs-comment"># 在本例中in_size=512，也就是BATCH_SIZE的值。输入的x可以看成是512*1*28*28的张量。</span><br>        out = self.conv1(x) <span class="hljs-comment"># batch*1*28*28 -&gt; batch*10*24*24（28x28的图像经过一次核为5x5的卷积，输出变为24x24）</span><br>        out = F.relu(out) <span class="hljs-comment"># batch*10*24*24（激活函数ReLU不改变形状））</span><br>        out = F.max_pool2d(out, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># batch*10*24*24 -&gt; batch*10*12*12（2*2的池化层会减半）</span><br>        out = self.conv2(out) <span class="hljs-comment"># batch*10*12*12 -&gt; batch*20*10*10（再卷积一次，核的大小是3）</span><br>        out = F.relu(out) <span class="hljs-comment"># batch*20*10*10</span><br>        out = out.view(in_size, -<span class="hljs-number">1</span>) <span class="hljs-comment"># batch*20*10*10 -&gt; batch*2000（out的第二维是-1，说明是自动推算，本例中第二维是20*10*10）</span><br>        out = self.fc1(out) <span class="hljs-comment"># batch*2000 -&gt; batch*500</span><br>        out = F.relu(out) <span class="hljs-comment"># batch*500</span><br>        out = self.fc2(out) <span class="hljs-comment"># batch*500 -&gt; batch*10</span><br>        out = F.log_softmax(out, dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># 计算log(softmax(x))</span><br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>

<p>我们实例化一个网络，实例化后使用.to方法将网络移动到GPU</p>
<p>优化器我们也直接选择简单暴力的Adam</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = ConvNet().to(DEVICE)<br>optimizer = optim.Adam(model.parameters())<br></code></pre></td></tr></table></figure>

<h3 id="训练和测试"><a href="#训练和测试" class="headerlink" title="训练和测试"></a>训练和测试</h3><p>下面定义一下训练的函数，我们将训练的所有操作都封装到这个函数中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, device, train_loader, optimizer, epoch</span>):<br>    model.train()<br>    <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        data, target = data.to(device), target.to(device)<br>        optimizer.zero_grad()<br>        output = model(data)<br>        loss = F.nll_loss(output, target)<br>        loss.backward()<br>        optimizer.step()<br>        <span class="hljs-keyword">if</span>(batch_idx+<span class="hljs-number">1</span>)%<span class="hljs-number">30</span> == <span class="hljs-number">0</span>: <br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                epoch, batch_idx * <span class="hljs-built_in">len</span>(data), <span class="hljs-built_in">len</span>(train_loader.dataset),<br>                <span class="hljs-number">100.</span> * batch_idx / <span class="hljs-built_in">len</span>(train_loader), loss.item()))<br></code></pre></td></tr></table></figure>

<p>测试的操作也一样封装成一个函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">model, device, test_loader</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data)<br>            test_loss += F.nll_loss(output, target, reduction=<span class="hljs-string">&#x27;sum&#x27;</span>).item() <span class="hljs-comment"># 将一批的损失相加</span><br>            pred = output.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>] <span class="hljs-comment"># 找到概率最大的下标</span><br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>().item()<br><br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="hljs-built_in">format</span>(<br>        test_loss, correct, <span class="hljs-built_in">len</span>(test_loader.dataset),<br>        <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset)))<br></code></pre></td></tr></table></figure>

<p>下面开始训练，这里就体现出封装起来的好处了，只要写两行就可以了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, EPOCHS + <span class="hljs-number">1</span>):<br>    train(model, DEVICE, train_loader, optimizer, epoch)<br>    test(model, DEVICE, test_loader)<br></code></pre></td></tr></table></figure>

<p>我们看一下结果，准确率99%，没问题</p>
<p>如果你的模型连MNIST都搞不定，那么你的模型没有任何的价值</p>
<p>即使你的模型搞定了MNIST，你的模型也可能没有任何的价值</p>
<p>MNIST是一个很简单的数据集，由于它的局限性只能作为研究用途，对实际应用带来的价值非常有限。但是通过这个例子，我们可以完全了解一个实际项目的工作流程</p>
<p>我们找到数据集，对数据做预处理，定义我们的模型，调整超参数，测试训练，再通过训练结果对超参数进行调整或者对模型进行调整。</p>
<p>并且通过这个实战我们已经有了一个很好的模板，以后的项目都可以以这个模板为样例</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/blog/categories/%E8%AE%BA%E6%96%87/" class="category-chain-item">论文</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/blog/tags/%E8%AE%BA%E6%96%87%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%81pytorch/">#论文、深度学习、pytorch</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>PyTorch 快速上手</div>
      <div>https://yoonalis.github.io/blog/2023/11/22/PyTorch handbook/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Azure</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年11月22日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/blog/2023/11/29/Huggingface%20%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/" title="Huggingface 快速上手">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Huggingface 快速上手</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/blog/2023/10/10/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Linux常用命令">
                        <span class="hidden-mobile">Linux常用命令</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/blog/js/events.js" ></script>
<script  src="/blog/js/plugins.js" ></script>


  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/blog/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/blog/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/caidai.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/love.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/blog/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
