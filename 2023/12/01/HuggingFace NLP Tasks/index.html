

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/blog/img/favicon.jpg">
  <link rel="icon" href="/blog/img/favicon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Azure">
  <meta name="keywords" content="">
  
    <meta name="description" content="论文">
<meta property="og:type" content="article">
<meta property="og:title" content="HuggingFace NLP Tasks">
<meta property="og:url" content="https://yoonalis.github.io/blog/2023/12/01/HuggingFace%20NLP%20Tasks/index.html">
<meta property="og:site_name" content="Azure&#39;s blog">
<meta property="og:description" content="论文">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yoonalis.github.io/blog/img/huggingface2.jpg">
<meta property="article:published_time" content="2023-12-01T12:08:05.937Z">
<meta property="article:modified_time" content="2023-12-03T12:53:05.222Z">
<meta property="article:author" content="Azure">
<meta property="article:tag" content="论文、深度学习、nlp、huggingface">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://yoonalis.github.io/blog/img/huggingface2.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>HuggingFace NLP Tasks - Azure&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/blog/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/blog/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/blog/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"yoonalis.github.io","root":"/blog/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/blog/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/blog/js/utils.js" ></script>
  <script  src="/blog/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/blog/">
      <strong>Azure</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/album/">
                <i class="iconfont icon-images"></i>
                album
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/blog/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="HuggingFace NLP Tasks"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-12-01 20:08" pubdate>
          2023年12月1日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          39k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          322 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">HuggingFace NLP Tasks</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="HuggingFace-NLP-Tasks"><a href="#HuggingFace-NLP-Tasks" class="headerlink" title="HuggingFace NLP Tasks"></a>HuggingFace NLP Tasks</h1><blockquote>
<p>基于huggingface的自然语言处理实战任务</p>
<p>代码参考：<a target="_blank" rel="noopener" href="https://github.com/lansinuote/Huggingface_Task">https://github.com/lansinuote/Huggingface_Task</a></p>
</blockquote>
<h2 id="1、预测最后一个词"><a href="#1、预测最后一个词" class="headerlink" title="1、预测最后一个词"></a>1、预测最后一个词</h2><blockquote>
<p>最传统的预言模型任务</p>
</blockquote>
<h3 id="定义全局变量"><a href="#定义全局变量" class="headerlink" title="定义全局变量"></a>定义全局变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#全局变量</span><br>hub_token = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/root/hub_token.txt&#x27;</span>).read().strip()<br>repo_id = <span class="hljs-string">&#x27;lansinuote/nlp.2.predict_middle_word&#x27;</span><br>push_to_hub = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>



<h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br><span class="hljs-comment">#加载编码器</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;distilgpt2&#x27;</span>, use_fast=<span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(tokenizer)<br><br><span class="hljs-comment">#编码试算</span><br>tokenizer.batch_encode_plus([<br>    <span class="hljs-string">&#x27;hide new secretions from the parental units&#x27;</span>,<br>    <span class="hljs-string">&#x27;contains no wit , only labored gags&#x27;</span><br>])<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201200310825-20231201%2020:03:11.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201200310825" style="zoom:50%;" />

<blockquote>
<p>Attention_mask用来遮住暂时不用关注的部分</p>
</blockquote>
<h3 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataset</span>():<br>    <span class="hljs-comment">#加载数据</span><br>    dataset = load_dataset(path=<span class="hljs-string">&#x27;glue&#x27;</span>, name=<span class="hljs-string">&#x27;sst2&#x27;</span>)<br><br>    <span class="hljs-comment">#分词,同时删除多余的字段</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">data</span>):<br>        <span class="hljs-keyword">return</span> tokenizer.batch_encode_plus(data[<span class="hljs-string">&#x27;sentence&#x27;</span>])<br><br>    dataset = dataset.<span class="hljs-built_in">map</span>(f,<br>                          batched=<span class="hljs-literal">True</span>,<br>                          batch_size=<span class="hljs-number">1000</span>,<br>                          num_proc=<span class="hljs-number">4</span>,<br>                          remove_columns=[<span class="hljs-string">&#x27;sentence&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>]) <span class="hljs-comment"># 不需要label，直接将最后一个词作为label</span><br><br>    <span class="hljs-comment">#过滤掉太短的句子</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">data</span>):<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">len</span>(i) &gt;= <span class="hljs-number">8</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data[<span class="hljs-string">&#x27;input_ids&#x27;</span>]]<br><br>    dataset = dataset.<span class="hljs-built_in">filter</span>(f, batched=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">1000</span>, num_proc=<span class="hljs-number">4</span>)<br><br>    <span class="hljs-comment">#截断句子,同时整理成模型需要的格式</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">data</span>):<br>        data[<span class="hljs-string">&#x27;input_ids&#x27;</span>] = [i[:<span class="hljs-number">8</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data[<span class="hljs-string">&#x27;input_ids&#x27;</span>]]<br>        data[<span class="hljs-string">&#x27;attention_mask&#x27;</span>] = [[<span class="hljs-number">1</span>] * <span class="hljs-number">8</span>] * <span class="hljs-built_in">len</span>(data[<span class="hljs-string">&#x27;attention_mask&#x27;</span>])<br>        <span class="hljs-comment">#在模型中处理了偏移量问题,这里保持输入输出一致即可</span><br>        data[<span class="hljs-string">&#x27;labels&#x27;</span>] = data[<span class="hljs-string">&#x27;input_ids&#x27;</span>].copy()<br>        <span class="hljs-keyword">return</span> data<br><br>    dataset = dataset.<span class="hljs-built_in">map</span>(f, batched=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">1000</span>, num_proc=<span class="hljs-number">4</span>)<br><br>    <span class="hljs-keyword">return</span> dataset<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    dataset = get_dataset()<br>    dataset.push_to_hub(repo_id=repo_id, token=hub_token)<br><br><span class="hljs-comment">#直接使用处理好的数据集</span><br>dataset = load_dataset(path=repo_id)<br><br>dataset, dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201201602543-20231201%2020:16:02.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201201602543" style="zoom:50%;" />

<h3 id="数据集加载器"><a href="#数据集加载器" class="headerlink" title="数据集加载器"></a>数据集加载器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers.data.data_collator <span class="hljs-keyword">import</span> default_data_collator<br><br><span class="hljs-comment">#数据加载器</span><br>loader = torch.utils.data.DataLoader(<br>    dataset=dataset[<span class="hljs-string">&#x27;train&#x27;</span>],<br>    batch_size=<span class="hljs-number">8</span>, <span class="hljs-comment"># 一个数据批次8条数据</span><br>    collate_fn=default_data_collator,<br>    shuffle=<span class="hljs-literal">True</span>,<br>    drop_last=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-built_in">len</span>(loader), data<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203205000947-20231203%2020:50:01.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203205000947" style="zoom:50%;" />

<h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, GPT2Model, PreTrainedModel, PretrainedConfig<br><br><span class="hljs-comment">#加载模型</span><br><span class="hljs-comment">#model = AutoModelForCausalLM.from_pretrained(&#x27;distilgpt2&#x27;)</span><br><br><br><span class="hljs-comment">#定义下游任务模型 fine-tune方式，backbone也会训练</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(<span class="hljs-title class_ inherited__">PreTrainedModel</span>):<br>    config_class = PretrainedConfig<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-built_in">super</span>().__init__(config)<br>        self.pretrained = GPT2Model.from_pretrained(<span class="hljs-string">&#x27;distilgpt2&#x27;</span>)<br>        self.fc = torch.nn.Linear(<span class="hljs-number">768</span>, tokenizer.vocab_size, bias=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-comment">#加载预训练模型的参数</span><br>        parameters = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;distilgpt2&#x27;</span>)<br>        self.fc.load_state_dict(parameters.lm_head.state_dict())<br><br>        self.criterion = torch.nn.CrossEntropyLoss()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, attention_mask, labels=<span class="hljs-literal">None</span></span>):<br>        logits = self.pretrained(input_ids=input_ids,<br>                                 attention_mask=attention_mask)<br>        logits = logits.last_hidden_state<br><br>        logits = self.fc(logits) <span class="hljs-comment"># 训练的重点：全连接网络</span><br><br>        loss = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> labels <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            shift_logits = logits[:, :-<span class="hljs-number">1</span>].reshape(-<span class="hljs-number">1</span>, tokenizer.vocab_size)<br>            shift_labels = labels[:, <span class="hljs-number">1</span>:].reshape(-<span class="hljs-number">1</span>)<br><br>            loss = self.criterion(shift_logits, shift_labels)<br><br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss, <span class="hljs-string">&#x27;logits&#x27;</span>: logits&#125;<br><br><br>model = Model(PretrainedConfig())<br><br><span class="hljs-comment">#统计参数量</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sum</span>(i.numel() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> model.parameters()) / <span class="hljs-number">10000</span>)<br><br>out = model(**data)<br><br>out[<span class="hljs-string">&#x27;loss&#x27;</span>], out[<span class="hljs-string">&#x27;logits&#x27;</span>].shape<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201204538345-20231201%2020:45:38.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201204538345" style="zoom:50%;" />

<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-keyword">from</span> transformers.optimization <span class="hljs-keyword">import</span> get_scheduler<br><br><br><span class="hljs-comment">#训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>) <span class="hljs-comment"># huggingface提供的Adam改良版</span><br>    scheduler = get_scheduler(name=<span class="hljs-string">&#x27;linear&#x27;</span>,<br>                              num_warmup_steps=<span class="hljs-number">0</span>,<br>                              num_training_steps=<span class="hljs-built_in">len</span>(loader),<br>                              optimizer=optimizer) <span class="hljs-comment"># 随着训练进行会不断调低learning_rate</span><br><br>    device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br>    model.train()<br>    model.to(device)<br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> data.keys():<br>            data[k] = data[k].to(device)<br><br>        out = model(**data)<br>        loss = out[<span class="hljs-string">&#x27;loss&#x27;</span>]<br><br>        loss.backward()<br>        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-number">1.0</span>) <span class="hljs-comment"># 梯度的范式裁剪：防止梯度过大/过小</span><br><br>        optimizer.step()<br>        scheduler.step()<br><br>        optimizer.zero_grad()<br>        model.zero_grad()<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            labels = data[<span class="hljs-string">&#x27;labels&#x27;</span>][:, <span class="hljs-number">1</span>:]<br>            out = out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>)[:, :-<span class="hljs-number">1</span>]<br><br>            correct = (labels == out).<span class="hljs-built_in">sum</span>().item()<br>            accuracy = correct / (<span class="hljs-number">8</span> * <span class="hljs-number">7</span>)<br><br>            lr = optimizer.state_dict()[<span class="hljs-string">&#x27;param_groups&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;lr&#x27;</span>]<br><br>            <span class="hljs-built_in">print</span>(i, loss.item(), accuracy, lr)<br><br>    torch.save(model, <span class="hljs-string">&#x27;models/预测最后一个词.model&#x27;</span>) <span class="hljs-comment"># 保存模型</span><br>    model.to(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    train()<br>    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201205007573-20231201%2020:50:07.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201205007573" style="zoom:50%;" />

<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#测试</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-comment">#数据加载器</span><br>    loader_test = torch.utils.data.DataLoader(<br>        dataset=dataset[<span class="hljs-string">&#x27;test&#x27;</span>],<br>        batch_size=<span class="hljs-number">8</span>,<br>        collate_fn=default_data_collator,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">True</span>,<br>    )<br><br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader_test):<br>        <span class="hljs-comment">#只计算最后一个词的正确率,这里先把最后一个词取出来</span><br>        label = data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][:, -<span class="hljs-number">1</span>].clone()<br><br>        <span class="hljs-comment">#从数据中抹除掉最后一个词,防止模型作弊</span><br>        data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][:, -<span class="hljs-number">1</span>] = <span class="hljs-number">0</span><br><br>        <span class="hljs-comment">#label就不需要了</span><br>        data[<span class="hljs-string">&#x27;labels&#x27;</span>][:, :] = <span class="hljs-number">0</span><br><br>        <span class="hljs-comment">#计算</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            out = model(**data)<br><br>        <span class="hljs-comment">#只计算最后一个词的正确率,因为有偏移量的关系,这里取的是倒数第二个词</span><br>        out = out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>)[:, -<span class="hljs-number">2</span>]<br><br>        correct += (label == out).<span class="hljs-built_in">sum</span>().item()<br>        total += <span class="hljs-number">8</span><br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(i)<br>            <span class="hljs-built_in">print</span>(label)<br>            <span class="hljs-built_in">print</span>(out)<br><br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">50</span>:<br>            <span class="hljs-keyword">break</span><br><br>    <span class="hljs-built_in">print</span>(correct / total)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):<br>        <span class="hljs-built_in">print</span>(tokenizer.decode(data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i, :-<span class="hljs-number">1</span>]))<br>        <span class="hljs-built_in">print</span>(tokenizer.decode(label[i]), tokenizer.decode(out[i]))<br>        <span class="hljs-built_in">print</span>()<br><br><span class="hljs-comment">#直接使用我训练好的模型</span><br>model = Model.from_pretrained(repo_id)<br>test()<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201205100643-20231201%2020:51:00.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201205100643" style="zoom:50%;" />

<h2 id="2、预测中间词"><a href="#2、预测中间词" class="headerlink" title="2、预测中间词"></a>2、预测中间词</h2><h3 id="定义全局变量-1"><a href="#定义全局变量-1" class="headerlink" title="定义全局变量"></a>定义全局变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#全局变量</span><br>hub_token = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/root/hub_token.txt&#x27;</span>).read().strip()<br>repo_id = <span class="hljs-string">&#x27;lansinuote/nlp.2.predict_middle_word&#x27;</span><br>push_to_hub = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<h3 id="编码器-1"><a href="#编码器-1" class="headerlink" title="编码器"></a>编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br><span class="hljs-comment">#加载编码器</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;distilroberta-base&#x27;</span>, use_fast=<span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(tokenizer)<br><br><span class="hljs-comment">#编码试算</span><br>tokenizer.batch_encode_plus([<br>    <span class="hljs-string">&#x27;hide new secretions from the parental units&#x27;</span>,<br>    <span class="hljs-string">&#x27;contains no wit , only labored gags&#x27;</span><br>])<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201210450230-20231201%2021:04:50.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201210450230" style="zoom:50%;" />

<h3 id="加载数据集-1"><a href="#加载数据集-1" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataset</span>():<br>    <span class="hljs-comment">#加载数据</span><br>    dataset = load_dataset(path=<span class="hljs-string">&#x27;glue&#x27;</span>, name=<span class="hljs-string">&#x27;sst2&#x27;</span>) <span class="hljs-comment"># sst2是一个情感分类数据集，本实战仅使用文本</span><br><br>    <span class="hljs-comment">#分词,同时删除多余的字段</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">data</span>):<br>        <span class="hljs-keyword">return</span> tokenizer.batch_encode_plus(data[<span class="hljs-string">&#x27;sentence&#x27;</span>])<br><br>    dataset = dataset.<span class="hljs-built_in">map</span>(f,<br>                          batched=<span class="hljs-literal">True</span>,<br>                          batch_size=<span class="hljs-number">1000</span>,<br>                          num_proc=<span class="hljs-number">4</span>,<br>                          remove_columns=[<span class="hljs-string">&#x27;sentence&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>])<br><br>    <span class="hljs-comment">#过滤掉太短的句子</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">data</span>):<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">len</span>(i) &gt;= <span class="hljs-number">9</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data[<span class="hljs-string">&#x27;input_ids&#x27;</span>]]<br><br>    dataset = dataset.<span class="hljs-built_in">filter</span>(f, batched=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">1000</span>, num_proc=<span class="hljs-number">4</span>)<br><br>    <span class="hljs-comment">#截断句子,同时整理成模型需要的格式</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">data</span>):<br>        b = <span class="hljs-built_in">len</span>(data[<span class="hljs-string">&#x27;input_ids&#x27;</span>])<br>        data[<span class="hljs-string">&#x27;labels&#x27;</span>] = data[<span class="hljs-string">&#x27;attention_mask&#x27;</span>].copy()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(b):<br>            <span class="hljs-comment">#裁剪长度到9</span><br>            data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i] = data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i][:<span class="hljs-number">9</span>]<br>            data[<span class="hljs-string">&#x27;attention_mask&#x27;</span>][i] = [<span class="hljs-number">1</span>] * <span class="hljs-number">9</span><br>            data[<span class="hljs-string">&#x27;labels&#x27;</span>][i] = [-<span class="hljs-number">100</span>] * <span class="hljs-number">9</span><br><br>            <span class="hljs-comment">#input_ids最后一位是2，特殊符号eos</span><br>            data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i][-<span class="hljs-number">1</span>] = <span class="hljs-number">2</span><br><br>            <span class="hljs-comment">#每一句话第4个词为mask</span><br>            <span class="hljs-comment">#tokenizer.get_vocab()[&#x27;&lt;mask&gt;&#x27;] -&gt; 50264</span><br>            data[<span class="hljs-string">&#x27;labels&#x27;</span>][i][<span class="hljs-number">4</span>] = data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i][<span class="hljs-number">4</span>]<br>            data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i][<span class="hljs-number">4</span>] = <span class="hljs-number">50264</span><br><br>        <span class="hljs-keyword">return</span> data<br><br>    dataset = dataset.<span class="hljs-built_in">map</span>(f, batched=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">1000</span>, num_proc=<span class="hljs-number">4</span>)<br>    <br>    <span class="hljs-keyword">return</span> dataset<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    dataset = get_dataset()<br>    dataset.push_to_hub(repo_id=repo_id, token=hub_token)<br><br><span class="hljs-comment">#直接使用我处理好的数据集</span><br>dataset = load_dataset(path=repo_id)<br><br>dataset, dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201210616470-20231201%2021:06:16.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201210616470" style="zoom:50%;" />

<h3 id="数据集加载器-1"><a href="#数据集加载器-1" class="headerlink" title="数据集加载器"></a>数据集加载器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers.data.data_collator <span class="hljs-keyword">import</span> default_data_collator<br><br><span class="hljs-comment">#能够实现随机mask的collate_fn</span><br><span class="hljs-comment">#如果要使用这个工具类,在数据预处理时就不需要设置数据中的mask,然后让labels=input_ids.copy即可</span><br><span class="hljs-comment">#from transformers import DataCollatorForLanguageModeling</span><br><span class="hljs-comment">#data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm_probability=0.1)</span><br><br><span class="hljs-comment">#数据加载器</span><br>loader = torch.utils.data.DataLoader(<br>    dataset=dataset[<span class="hljs-string">&#x27;train&#x27;</span>],<br>    batch_size=<span class="hljs-number">8</span>,<br>    collate_fn=default_data_collator, <span class="hljs-comment"># huggingface提供</span><br>    shuffle=<span class="hljs-literal">True</span>,<br>    drop_last=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-built_in">len</span>(loader), data<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231201211231036-20231201%2021:12:31.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231201211231036" style="zoom:50%;" />

<h3 id="定义模型-1"><a href="#定义模型-1" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, RobertaModel, PreTrainedModel, PretrainedConfig<br><br><span class="hljs-comment">#加载模型</span><br><span class="hljs-comment">#model = AutoModelForCausalLM.from_pretrained(&#x27;distilroberta-base&#x27;)</span><br><br><br><span class="hljs-comment">#定义下游任务模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(<span class="hljs-title class_ inherited__">PreTrainedModel</span>):<br>    config_class = PretrainedConfig<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-built_in">super</span>().__init__(config)<br>        self.pretrained = RobertaModel.from_pretrained(<span class="hljs-string">&#x27;distilroberta-base&#x27;</span>) <span class="hljs-comment"># backbone</span><br><br>        decoder = torch.nn.Linear(<span class="hljs-number">768</span>, tokenizer.vocab_size) <span class="hljs-comment"># 解码器，输出与字典尺寸一致</span><br>        decoder.bias = torch.nn.Parameter(torch.zeros(tokenizer.vocab_size))<br><br>        self.fc = torch.nn.Sequential(<br>            torch.nn.Linear(<span class="hljs-number">768</span>, <span class="hljs-number">768</span>),<br>            torch.nn.GELU(),<br>            torch.nn.LayerNorm(<span class="hljs-number">768</span>, eps=<span class="hljs-number">1e-5</span>),<br>            decoder, <span class="hljs-comment"># 最后进行decoder的计算</span><br>        ) <span class="hljs-comment"># 全连接</span><br><br>        <span class="hljs-comment">#加载预训练模型的参数 fine tune</span><br>        parameters = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;distilroberta-base&#x27;</span>)<br>        self.fc[<span class="hljs-number">0</span>].load_state_dict(parameters.lm_head.dense.state_dict())<br>        self.fc[<span class="hljs-number">2</span>].load_state_dict(parameters.lm_head.layer_norm.state_dict())<br>        self.fc[<span class="hljs-number">3</span>].load_state_dict(parameters.lm_head.decoder.state_dict())<br><br>        self.criterion = torch.nn.CrossEntropyLoss()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, attention_mask, labels=<span class="hljs-literal">None</span></span>):<br>        logits = self.pretrained(input_ids=input_ids,<br>                                 attention_mask=attention_mask)<br>        logits = logits.last_hidden_state<br><br>        logits = self.fc(logits)<br><br>        loss = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> labels <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            shifted_logits = logits[:, :-<span class="hljs-number">1</span>].reshape(-<span class="hljs-number">1</span>, tokenizer.vocab_size)<br>            shifted_labels = labels[:, <span class="hljs-number">1</span>:].reshape(-<span class="hljs-number">1</span>)<br><br>            loss = self.criterion(shifted_logits, shifted_labels)<br><br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss, <span class="hljs-string">&#x27;logits&#x27;</span>: logits&#125;<br><br><br>model = Model(PretrainedConfig())<br><br><span class="hljs-comment">#统计参数量</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sum</span>(i.numel() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> model.parameters()) / <span class="hljs-number">10000</span>)<br><br>out = model(**data)<br><br>out[<span class="hljs-string">&#x27;loss&#x27;</span>], out[<span class="hljs-string">&#x27;logits&#x27;</span>].shape<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231202152510067-20231202%2015:25:10.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231202152510067" style="zoom:50%;" />

<h3 id="定义测试函数"><a href="#定义测试函数" class="headerlink" title="定义测试函数"></a>定义测试函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#测试</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br><br>    loader_test = torch.utils.data.DataLoader(<br>        dataset=dataset[<span class="hljs-string">&#x27;test&#x27;</span>],<br>        batch_size=<span class="hljs-number">8</span>,<br>        collate_fn=default_data_collator,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">True</span>,<br>    )<br><br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader_test):<br>        <span class="hljs-comment">#保存下数据中的label,后面计算正确率要用</span><br>        label = data[<span class="hljs-string">&#x27;labels&#x27;</span>][:, <span class="hljs-number">4</span>].clone()<br><br>        <span class="hljs-comment">#从数据中抹除掉label,防止模型作弊</span><br>        data[<span class="hljs-string">&#x27;labels&#x27;</span>] = <span class="hljs-literal">None</span><br><br>        <span class="hljs-comment">#计算</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            out = model(**data)<br><br>        <span class="hljs-comment">#[8, 10, 50265] -&gt; [8, 10]</span><br>        out = out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>)[:, <span class="hljs-number">4</span>]<br><br>        correct += (label == out).<span class="hljs-built_in">sum</span>().item()<br>        total += <span class="hljs-number">8</span><br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(i)<br>            <span class="hljs-built_in">print</span>(label)<br>            <span class="hljs-built_in">print</span>(out)<br><br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">50</span>:<br>            <span class="hljs-keyword">break</span><br><br>    <span class="hljs-built_in">print</span>(correct / total)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):<br>        <span class="hljs-built_in">print</span>(tokenizer.decode(data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i]))<br>        <span class="hljs-built_in">print</span>(tokenizer.decode(label[i]), tokenizer.decode(out[i]))<br><br></code></pre></td></tr></table></figure>

<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-keyword">from</span> transformers.optimization <span class="hljs-keyword">import</span> get_scheduler<br><br><br><span class="hljs-comment">#训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br>    scheduler = get_scheduler(name=<span class="hljs-string">&#x27;linear&#x27;</span>,<br>                              num_warmup_steps=<span class="hljs-number">0</span>,<br>                              num_training_steps=<span class="hljs-built_in">len</span>(loader),<br>                              optimizer=optimizer)<br><br>    device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br>    model.train()<br>    model.to(device)<br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> data.keys():<br>            data[k] = data[k].to(device)<br>        out = model(**data)<br>        loss = out[<span class="hljs-string">&#x27;loss&#x27;</span>]<br><br>        loss.backward()<br>        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-number">1.0</span>)<br><br>        optimizer.step()<br>        scheduler.step()<br><br>        optimizer.zero_grad()<br>        model.zero_grad()<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            label = data[<span class="hljs-string">&#x27;labels&#x27;</span>][:, <span class="hljs-number">4</span>]<br>            out = out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>)[:, <span class="hljs-number">4</span>]<br><br>            correct = (label == out).<span class="hljs-built_in">sum</span>().item()<br>            accuracy = correct / <span class="hljs-number">8</span><br><br>            lr = optimizer.state_dict()[<span class="hljs-string">&#x27;param_groups&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;lr&#x27;</span>]<br><br>            <span class="hljs-built_in">print</span>(i, loss.item(), accuracy, lr)<br><br>    model.to(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    train()<br>    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231202153845980-20231202%2015:38:46.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231202153845980" style="zoom:50%;" />

<h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#直接使用我训练好的模型</span><br>model = Model.from_pretrained(repo_id)<br><br>test()<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231202153924620-20231202%2015:39:24.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231202153924620" style="zoom:50%;" />

<h2 id="3、阅读理解（问答）"><a href="#3、阅读理解（问答）" class="headerlink" title="3、阅读理解（问答）"></a>3、阅读理解（问答）</h2><blockquote>
<p>问题的答案要出现在文档中</p>
</blockquote>
<h3 id="定义全局变量-2"><a href="#定义全局变量-2" class="headerlink" title="定义全局变量"></a>定义全局变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#全局变量</span><br>hub_token = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/root/hub_token.txt&#x27;</span>).read().strip()<br>repo_id = <span class="hljs-string">&#x27;lansinuote/nlp.3.reading_for_understanding&#x27;</span><br>push_to_hub = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<h3 id="编码器-2"><a href="#编码器-2" class="headerlink" title="编码器"></a>编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br><span class="hljs-comment">#加载分词工具</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>)<br><br>tokenizer(<span class="hljs-string">&#x27;What is your name?&#x27;</span>, <span class="hljs-string">&#x27;My name is Sylvain.&#x27;</span>)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203163056330-20231203%2016:30:57.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203163056330" style="zoom:50%;" />

<h3 id="squad数据的处理函数"><a href="#squad数据的处理函数" class="headerlink" title="squad数据的处理函数"></a>squad数据的处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#可以直接用我处理好的数据集,这段代码可以跳过不看</span><br><span class="hljs-comment">#从官方教程里抄出来的函数,总之就是squad数据的处理函数,过程非常复杂,即使是官方的实现也是有问题的,我实在没本事写这个</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_train_features</span>(<span class="hljs-params">examples</span>):<br>    <span class="hljs-comment"># Some of the questions have lots of whitespace on the left, which is not useful and will make the</span><br>    <span class="hljs-comment"># truncation of the context fail (the tokenized question will take a lots of space). So we remove that</span><br>    <span class="hljs-comment"># left whitespace</span><br>    examples[<span class="hljs-string">&quot;question&quot;</span>] = [q.lstrip() <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;question&quot;</span>]]<br><br>    <span class="hljs-comment"># Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results</span><br>    <span class="hljs-comment"># in one example possible giving several features when a context is long, each of those features having a</span><br>    <span class="hljs-comment"># context that overlaps a bit the context of the previous feature.</span><br>    tokenized_examples = tokenizer(<br>        examples[<span class="hljs-string">&#x27;question&#x27;</span>],<br>        examples[<span class="hljs-string">&#x27;context&#x27;</span>],<br>        truncation=<span class="hljs-string">&#x27;only_second&#x27;</span>,<br>        max_length=<span class="hljs-number">384</span>,<br>        stride=<span class="hljs-number">128</span>,<br>        return_overflowing_tokens=<span class="hljs-literal">True</span>,<br>        return_offsets_mapping=<span class="hljs-literal">True</span>,<br>        padding=<span class="hljs-string">&#x27;max_length&#x27;</span>,<br>    )<br><br>    <span class="hljs-comment"># Since one example might give us several features if it has a long context, we need a map from a feature to</span><br>    <span class="hljs-comment"># its corresponding example. This key gives us just that.</span><br>    sample_mapping = tokenized_examples.pop(<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>)<br>    <span class="hljs-comment"># The offset mappings will give us a map from token to character position in the original context. This will</span><br>    <span class="hljs-comment"># help us compute the start_positions and end_positions.</span><br>    offset_mapping = tokenized_examples.pop(<span class="hljs-string">&quot;offset_mapping&quot;</span>)<br><br>    <span class="hljs-comment"># Let&#x27;s label those examples!</span><br>    tokenized_examples[<span class="hljs-string">&quot;start_positions&quot;</span>] = []<br>    tokenized_examples[<span class="hljs-string">&quot;end_positions&quot;</span>] = []<br><br>    <span class="hljs-keyword">for</span> i, offsets <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(offset_mapping):<br>        <span class="hljs-comment"># We will label impossible answers with the index of the CLS token.</span><br>        input_ids = tokenized_examples[<span class="hljs-string">&quot;input_ids&quot;</span>][i]<br>        cls_index = input_ids.index(tokenizer.cls_token_id)<br><br>        <span class="hljs-comment"># Grab the sequence corresponding to that example (to know what is the context and what is the question).</span><br>        sequence_ids = tokenized_examples.sequence_ids(i)<br><br>        <span class="hljs-comment"># One example can give several spans, this is the index of the example containing this span of text.</span><br>        sample_index = sample_mapping[i]<br>        answers = examples[<span class="hljs-string">&quot;answers&quot;</span>][sample_index]<br>        <span class="hljs-comment"># If no answers are given, set the cls_index as answer.</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(answers[<span class="hljs-string">&quot;answer_start&quot;</span>]) == <span class="hljs-number">0</span>:<br>            tokenized_examples[<span class="hljs-string">&quot;start_positions&quot;</span>].append(cls_index)<br>            tokenized_examples[<span class="hljs-string">&quot;end_positions&quot;</span>].append(cls_index)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># Start/end character index of the answer in the text.</span><br>            start_char = answers[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>]<br>            end_char = start_char + <span class="hljs-built_in">len</span>(answers[<span class="hljs-string">&quot;text&quot;</span>][<span class="hljs-number">0</span>])<br><br>            <span class="hljs-comment"># Start token index of the current span in the text.</span><br>            token_start_index = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">while</span> sequence_ids[token_start_index] != <span class="hljs-number">1</span>:<br>                token_start_index += <span class="hljs-number">1</span><br><br>            <span class="hljs-comment"># End token index of the current span in the text.</span><br>            token_end_index = <span class="hljs-built_in">len</span>(input_ids) - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> sequence_ids[token_end_index] != <span class="hljs-number">1</span>:<br>                token_end_index -= <span class="hljs-number">1</span><br><br>            <span class="hljs-comment"># Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (offsets[token_start_index][<span class="hljs-number">0</span>] &lt;= start_char<br>                    <span class="hljs-keyword">and</span> offsets[token_end_index][<span class="hljs-number">1</span>] &gt;= end_char):<br>                tokenized_examples[<span class="hljs-string">&quot;start_positions&quot;</span>].append(cls_index)<br>                tokenized_examples[<span class="hljs-string">&quot;end_positions&quot;</span>].append(cls_index)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># Otherwise move the token_start_index and token_end_index to the two ends of the answer.</span><br>                <span class="hljs-comment"># Note: we could go after the last offset if the answer is the last word (edge case).</span><br>                <span class="hljs-keyword">while</span> token_start_index &lt; <span class="hljs-built_in">len</span>(offsets) <span class="hljs-keyword">and</span> offsets[<br>                        token_start_index][<span class="hljs-number">0</span>] &lt;= start_char:<br>                    token_start_index += <span class="hljs-number">1</span><br>                tokenized_examples[<span class="hljs-string">&quot;start_positions&quot;</span>].append(<br>                    token_start_index - <span class="hljs-number">1</span>)<br>                <span class="hljs-keyword">while</span> offsets[token_end_index][<span class="hljs-number">1</span>] &gt;= end_char:<br>                    token_end_index -= <span class="hljs-number">1</span><br>                tokenized_examples[<span class="hljs-string">&quot;end_positions&quot;</span>].append(token_end_index + <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> tokenized_examples<br><br><br><span class="hljs-comment">#虚拟一批数据</span><br>datas = &#123;<br>    <span class="hljs-string">&#x27;id&#x27;</span>: [<br>        <span class="hljs-string">&#x27;570d88cdfed7b91900d461f1&#x27;</span>, <span class="hljs-string">&#x27;57268432f1498d1400e8e25e&#x27;</span>,<br>        <span class="hljs-string">&#x27;570d675db3d812140066d84e&#x27;</span><br>    ],<br>    <span class="hljs-string">&#x27;title&#x27;</span>:<br>    [<span class="hljs-string">&#x27;United_States_Army&#x27;</span>, <span class="hljs-string">&#x27;East_India_Company&#x27;</span>, <span class="hljs-string">&#x27;Franco-Prussian_War&#x27;</span>],<br>    <span class="hljs-string">&#x27;context&#x27;</span>: [<br>        <span class="hljs-string">&quot;The United States Army is made up of three components: the active component, the Regular Army; and two reserve components, the Army National Guard and the Army Reserve. Both reserve components are primarily composed of part-time soldiers who train once a month, known as battle assemblies or unit training assemblies (UTAs), and conduct two to three weeks of annual training each year. Both the Regular Army and the Army Reserve are organized under Title 10 of the United States Code, while the National Guard is organized under Title 32. While the Army National Guard is organized, trained and equipped as a component of the U.S. Army, when it is not in federal service it is under the command of individual state and territorial governors; the District of Columbia National Guard, however, reports to the U.S. President, not the district&#x27;s mayor, even when not federalized. Any or all of the National Guard can be federalized by presidential order and against the governor&#x27;s wishes.&quot;</span>,<br>        <span class="hljs-string">&#x27;The East India Company\&#x27;s arms, granted in 1698, were: &quot;Argent a cross Gules; in the dexter chief quarter an escutcheon of the arms of France and England quarterly, the shield ornamentally and regally crowned Or.&quot; The crest was: &quot;A lion rampant guardant Or holding between the forepaws a regal crown proper.&quot; The supporters were: &quot;Two lions rampant guardant Or, each supporting a banner erect Argent, charged with a cross Gules.&quot; The motto was AUSPICIO REGIS ET SENATUS ANGLIÆ (Latin: By right of the King and the Senate of England).&#x27;</span>,<br>        <span class="hljs-string">&quot;With the defeat of the First Army, Prince Frederick Charles ordered a massed artillery attack against Canrobert&#x27;s position at St. Privat to prevent the Guards attack from failing too. At 19:00 the 3rd Division of Fransecky&#x27;s II Corps of the Second Army advanced across Ravine while the XII Corps cleared out the nearby town of Roncourt and with the survivors of the 1st Guards Infantry Division launched a fresh attack against the ruins of St. Privat. At 20:00, the arrival of the Prussian 4th Infantry Division of the II Corps and with the Prussian right flank on Mance Ravine, the line stabilised. By then, the Prussians of the 1st Guards Infantry Division and the XII and II Corps captured St. Privat forcing the decimated French forces to withdraw. With the Prussians exhausted from the fighting, the French were now able to mount a counter-attack. General Bourbaki, however, refused to commit the reserves of the French Old Guard to the battle because, by that time, he considered the overall situation a &#x27;defeat&#x27;. By 22:00, firing largely died down across the battlefield for the night. The next morning, the French Army of the Rhine, rather than resume the battle with an attack of its own against the battle-weary German armies, retreated to Metz where they were besieged and forced to surrender two months later.&quot;</span><br>    ],<br>    <span class="hljs-string">&#x27;question&#x27;</span>: [<br>        <span class="hljs-string">&#x27;What are UTAs?&#x27;</span>, <span class="hljs-string">&#x27;how many lions were on the EIC arms&#x27;</span>,<br>        <span class="hljs-string">&#x27;The surving soldiers of the 1st Guards Infantry Division launched a new attack against what?&#x27;</span><br>    ],<br>    <span class="hljs-string">&#x27;answers&#x27;</span>: [&#123;<br>        <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;unit training assemblies&#x27;</span>],<br>        <span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">292</span>]<br>    &#125;, &#123;<br>        <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;Two&#x27;</span>],<br>        <span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">330</span>]<br>    &#125;, &#123;<br>        <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;ruins of St. Privat&#x27;</span>],<br>        <span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">431</span>]<br>    &#125;]<br>&#125;<br><br><span class="hljs-comment">#调用squad数据预处理函数</span><br>features = prepare_train_features(datas)<br><br><span class="hljs-comment">#先看看处理后的结果</span><br><span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> features.items():<br>    <span class="hljs-built_in">print</span>(k, <span class="hljs-built_in">len</span>(v), v)<br>    <span class="hljs-built_in">print</span>()<br><br><span class="hljs-comment">#还原成文字查看,很显然,即使是huggingface的实现也是有问题的</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(features[<span class="hljs-string">&#x27;input_ids&#x27;</span>])):<br>    input_ids = features[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i]<br>    start_positions = features[<span class="hljs-string">&#x27;start_positions&#x27;</span>][i]<br>    end_positions = features[<span class="hljs-string">&#x27;end_positions&#x27;</span>][i]<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;问题和文本&#x27;</span>)<br>    question_and_context = tokenizer.decode(input_ids)<br>    <span class="hljs-built_in">print</span>(question_and_context)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;答案&#x27;</span>)<br>    answer = tokenizer.decode(input_ids[start_positions:end_positions])<br>    <span class="hljs-built_in">print</span>(answer)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;原答案&#x27;</span>)<br>    original_answer = datas[<span class="hljs-string">&#x27;answers&#x27;</span>][i][<span class="hljs-string">&#x27;text&#x27;</span>][<span class="hljs-number">0</span>]<br>    <span class="hljs-built_in">print</span>(original_answer)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203205031056-20231203%2020:50:31.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203205031056" style="zoom:50%;" />

<h3 id="加载数据集-2"><a href="#加载数据集-2" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataset</span>():<br>    <span class="hljs-comment">#加载数据集</span><br>    dataset = load_dataset(<span class="hljs-string">&#x27;squad&#x27;</span>)<br><br>    <span class="hljs-comment">#采样,数据量太大了跑不动</span><br>    dataset[<span class="hljs-string">&#x27;train&#x27;</span>] = dataset[<span class="hljs-string">&#x27;train&#x27;</span>].shuffle().select(<span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>))<br>    dataset[<span class="hljs-string">&#x27;validation&#x27;</span>] = dataset[<span class="hljs-string">&#x27;validation&#x27;</span>].shuffle().select(<span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>))<br><br>    <span class="hljs-built_in">print</span>(dataset, dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-number">0</span>])<br><br>    <span class="hljs-comment">#应用预处理函数</span><br>    dataset = dataset.<span class="hljs-built_in">map</span>(<br>        function=prepare_train_features,<br>        batched=<span class="hljs-literal">True</span>,<br>        remove_columns=[<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>])<br><br>    <span class="hljs-keyword">return</span> dataset<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    dataset = get_dataset()<br>    dataset.push_to_hub(repo_id=repo_id, token=hub_token)<br><br><span class="hljs-comment">#直接使用我处理好的数据集</span><br>dataset = load_dataset(path=repo_id)<br><br><span class="hljs-built_in">print</span>(dataset, dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>

<h3 id="数据集加载器-2"><a href="#数据集加载器-2" class="headerlink" title="数据集加载器"></a>数据集加载器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers.data.data_collator <span class="hljs-keyword">import</span> default_data_collator<br><br><span class="hljs-comment">#数据加载器</span><br>loader = torch.utils.data.DataLoader(<br>    dataset=dataset[<span class="hljs-string">&#x27;train&#x27;</span>],<br>    batch_size=<span class="hljs-number">8</span>,<br>    collate_fn=default_data_collator,<br>    shuffle=<span class="hljs-literal">True</span>,<br>    drop_last=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-built_in">len</span>(loader), data<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203172821699-20231203%2017:28:22.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203172821699" style="zoom:50%;" />

<h3 id="定义模型-2"><a href="#定义模型-2" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForQuestionAnswering, DistilBertModel, PreTrainedModel, PretrainedConfig<br><br><span class="hljs-comment">#加载模型</span><br><span class="hljs-comment">#model = AutoModelForQuestionAnswering.from_pretrained(&#x27;distilbert-base-uncased&#x27;)</span><br><br><br><span class="hljs-comment">#定义下游任务模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(<span class="hljs-title class_ inherited__">PreTrainedModel</span>):<br>    config_class = PretrainedConfig<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-built_in">super</span>().__init__(config)<br>        self.pretrained = DistilBertModel.from_pretrained(<br>            <span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>) <span class="hljs-comment"># 模型backbone</span><br><br>        self.fc = torch.nn.Sequential(torch.nn.Dropout(<span class="hljs-number">0.1</span>),<br>                                      torch.nn.Linear(<span class="hljs-number">768</span>, <span class="hljs-number">2</span>)) <span class="hljs-comment"># 输出结果是两个数字，分别是起点和终点</span><br><br>        <span class="hljs-comment">#加载预训练模型的参数</span><br>        parameters = AutoModelForQuestionAnswering.from_pretrained(<br>            <span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>)<br>        self.fc[<span class="hljs-number">1</span>].load_state_dict(parameters.qa_outputs.state_dict())<br><br>    <span class="hljs-comment"># 模型计算部分</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, attention_mask, start_positions,</span><br><span class="hljs-params">                end_positions</span>):<br>        <span class="hljs-comment">#[b, lens] -&gt; [b, lens, 768]</span><br>        logits = self.pretrained(input_ids=input_ids,<br>                                 attention_mask=attention_mask)<br>        logits = logits.last_hidden_state<br><br>        <span class="hljs-comment">#[b, lens, 768] -&gt; [b, lens, 2] 将抽取完的特征送到全连接计算开始和结束位置</span><br>        logits = self.fc(logits)<br><br>        <span class="hljs-comment">#[b, lens, 2] -&gt; [b, lens, 1],[b, lens, 1]</span><br>        start_logits, end_logits = logits.split(<span class="hljs-number">1</span>, dim=<span class="hljs-number">2</span>)<br><br>        <span class="hljs-comment">#[b, lens, 1] -&gt; [b, lens]</span><br>        start_logits = start_logits.squeeze(<span class="hljs-number">2</span>)<br>        end_logits = end_logits.squeeze(<span class="hljs-number">2</span>)<br><br>        <span class="hljs-comment">#起点和终点都不能超出句子的长度</span><br>        lens = start_logits.shape[<span class="hljs-number">1</span>]<br>        start_positions = start_positions.clamp(<span class="hljs-number">0</span>, lens)<br>        end_positions = end_positions.clamp(<span class="hljs-number">0</span>, lens)<br><br>        criterion = torch.nn.CrossEntropyLoss(ignore_index=lens) <span class="hljs-comment"># 超出范围的答案不计算loss</span><br><br>        start_loss = criterion(start_logits, start_positions)<br>        end_loss = criterion(end_logits, end_positions)<br>        loss = (start_loss + end_loss) / <span class="hljs-number">2</span><br><br>        <span class="hljs-keyword">return</span> &#123;<br>            <span class="hljs-string">&#x27;loss&#x27;</span>: loss,<br>            <span class="hljs-string">&#x27;start_logits&#x27;</span>: start_logits,<br>            <span class="hljs-string">&#x27;end_logits&#x27;</span>: end_logits<br>        &#125;<br><br><br>model = Model(PretrainedConfig())<br><br><span class="hljs-comment">#统计参数量</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sum</span>(i.numel() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> model.parameters()) / <span class="hljs-number">10000</span>)<br><br>out = model(**data)<br><br>out[<span class="hljs-string">&#x27;loss&#x27;</span>], out[<span class="hljs-string">&#x27;start_logits&#x27;</span>].shape, out[<span class="hljs-string">&#x27;end_logits&#x27;</span>].shape<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203172921219-20231203%2017:29:21.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203172921219" style="zoom:50%;" />

<h3 id="定义测试函数-1"><a href="#定义测试函数-1" class="headerlink" title="定义测试函数"></a>定义测试函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#测试</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-comment">#数据加载器</span><br>    loader_val = torch.utils.data.DataLoader(<br>        dataset=dataset[<span class="hljs-string">&#x27;validation&#x27;</span>],<br>        batch_size=<span class="hljs-number">16</span>,<br>        collate_fn=default_data_collator,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">True</span>,<br>    )<br><br>    start_offset = <span class="hljs-number">0</span><br>    end_offset = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader_val):<br>        <span class="hljs-comment">#计算</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            out = model(**data)<br><br>        start_offset += (out[<span class="hljs-string">&#x27;start_logits&#x27;</span>].argmax(dim=<span class="hljs-number">1</span>) -<br>                         data[<span class="hljs-string">&#x27;start_positions&#x27;</span>]).<span class="hljs-built_in">abs</span>().<span class="hljs-built_in">sum</span>().item()<br><br>        end_offset += (out[<span class="hljs-string">&#x27;end_logits&#x27;</span>].argmax(dim=<span class="hljs-number">1</span>) -<br>                       data[<span class="hljs-string">&#x27;end_positions&#x27;</span>]).<span class="hljs-built_in">abs</span>().<span class="hljs-built_in">sum</span>().item()<br><br>        total += <span class="hljs-number">16</span><br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(i)<br><br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">50</span>:<br>            <span class="hljs-keyword">break</span><br><br>    <span class="hljs-built_in">print</span>(start_offset / total, end_offset / total)<br><br>    start_logits = out[<span class="hljs-string">&#x27;start_logits&#x27;</span>].argmax(dim=<span class="hljs-number">1</span>)<br>    end_logits = out[<span class="hljs-string">&#x27;end_logits&#x27;</span>].argmax(dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>        input_ids = data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i]<br><br>        pred_answer = input_ids[start_logits[i]:end_logits[i]]<br><br>        label_answer = input_ids[<br>            data[<span class="hljs-string">&#x27;start_positions&#x27;</span>][i]:data[<span class="hljs-string">&#x27;end_positions&#x27;</span>][i]]<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;input_ids=&#x27;</span>, tokenizer.decode(input_ids))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pred_answer=&#x27;</span>, tokenizer.decode(pred_answer))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;label_answer=&#x27;</span>, tokenizer.decode(label_answer))<br>        <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure>

<h3 id="训练-2"><a href="#训练-2" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-keyword">from</span> transformers.optimization <span class="hljs-keyword">import</span> get_scheduler<br><br><br><span class="hljs-comment">#训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br>    scheduler = get_scheduler(name=<span class="hljs-string">&#x27;linear&#x27;</span>,<br>                              num_warmup_steps=<span class="hljs-number">0</span>,<br>                              num_training_steps=<span class="hljs-built_in">len</span>(loader),<br>                              optimizer=optimizer)<br><br>    device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br>    model.train()<br>    model.to(device)<br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> data.keys():<br>            data[k] = data[k].to(device)<br>            <br>        out = model(**data)<br>        loss = out[<span class="hljs-string">&#x27;loss&#x27;</span>]<br><br>        loss.backward()<br>        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-number">1.0</span>)<br><br>        optimizer.step()<br>        scheduler.step()<br><br>        optimizer.zero_grad()<br>        model.zero_grad()<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            lr = optimizer.state_dict()[<span class="hljs-string">&#x27;param_groups&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;lr&#x27;</span>]<br><br>            start_offset = (out[<span class="hljs-string">&#x27;start_logits&#x27;</span>].argmax(dim=<span class="hljs-number">1</span>) -<br>                            data[<span class="hljs-string">&#x27;start_positions&#x27;</span>]).<span class="hljs-built_in">abs</span>().<span class="hljs-built_in">sum</span>().item() / <span class="hljs-number">8</span><br><br>            end_offset = (out[<span class="hljs-string">&#x27;end_logits&#x27;</span>].argmax(dim=<span class="hljs-number">1</span>) -<br>                          data[<span class="hljs-string">&#x27;end_positions&#x27;</span>]).<span class="hljs-built_in">abs</span>().<span class="hljs-built_in">sum</span>().item() / <span class="hljs-number">8</span><br><br>            <span class="hljs-built_in">print</span>(i, loss.item(), lr, start_offset, end_offset)<br><br>    model.to(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br>    <br><span class="hljs-keyword">if</span> push_to_hub:<br>    train()<br>    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203173543872-20231203%2017:35:44.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203173543872" style="zoom:50%;" />

<h3 id="测试-2"><a href="#测试-2" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#直接使用我训练好的模型</span><br>model = Model.from_pretrained(repo_id)<br><br>test()<br></code></pre></td></tr></table></figure>

<h2 id="4、文本摘要"><a href="#4、文本摘要" class="headerlink" title="4、文本摘要"></a>4、文本摘要</h2><h3 id="定义全局变量-3"><a href="#定义全局变量-3" class="headerlink" title="定义全局变量"></a>定义全局变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#全局变量</span><br>hub_token = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/root/hub_token.txt&#x27;</span>).read().strip()<br>repo_id = <span class="hljs-string">&#x27;lansinuote/nlp.4.summarization&#x27;</span><br>push_to_hub = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<h3 id="编码器-3"><a href="#编码器-3" class="headerlink" title="编码器"></a>编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br><span class="hljs-comment">#加载分词器</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;t5-small&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(tokenizer)<br><br><span class="hljs-comment">#编码试算</span><br><span class="hljs-built_in">print</span>(<br>    tokenizer.batch_encode_plus(<br>        [<span class="hljs-string">&#x27;Hello, this one sentence!&#x27;</span>, <span class="hljs-string">&#x27;This is another sentence.&#x27;</span>]))<br><br><span class="hljs-comment">#label的编码方式,但是试验结果是和input的编码方式一样,没有区别</span><br><span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():<br>    <span class="hljs-built_in">print</span>(<br>        tokenizer.batch_encode_plus(<br>            [<span class="hljs-string">&#x27;Hello, this one sentence!&#x27;</span>, <span class="hljs-string">&#x27;This is another sentence.&#x27;</span>]))<br></code></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203175301894-20231203%2017:53:02.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203175301894"></p>
<h3 id="加载数据集-3"><a href="#加载数据集-3" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataset</span>():<br>    <span class="hljs-comment">#加载数据集</span><br>    dataset = load_dataset(<span class="hljs-string">&#x27;xsum&#x27;</span>)<br><br>    <span class="hljs-comment">#采样,数据量太大了跑不动</span><br>    dataset[<span class="hljs-string">&#x27;train&#x27;</span>] = dataset[<span class="hljs-string">&#x27;train&#x27;</span>].shuffle(<span class="hljs-number">1</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">20000</span>))<br>    dataset[<span class="hljs-string">&#x27;validation&#x27;</span>] = dataset[<span class="hljs-string">&#x27;validation&#x27;</span>].shuffle(<span class="hljs-number">1</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>))<br>    dataset[<span class="hljs-string">&#x27;test&#x27;</span>] = dataset[<span class="hljs-string">&#x27;test&#x27;</span>].shuffle(<span class="hljs-number">1</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>))<br><br>    <span class="hljs-built_in">print</span>(dataset, dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-number">0</span>])<br><br>    <span class="hljs-comment">#数据预处理函数,分词</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">examples</span>):<br>        <span class="hljs-comment">#编码input</span><br>        data = tokenizer.batch_encode_plus(<br>            <span class="hljs-comment">#在输入的前面加summarize前缀,这个是h5模型识别任务类型的标识</span><br>            [<span class="hljs-string">&#x27;summarize: &#x27;</span> + i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&#x27;document&#x27;</span>]],<br>            max_length=<span class="hljs-number">1024</span>,<br>            truncation=<span class="hljs-literal">True</span>,<br>        )<br><br>        <span class="hljs-comment">#编码label</span><br>        <span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():<br>            data[<span class="hljs-string">&#x27;labels&#x27;</span>] = tokenizer.batch_encode_plus(<br>                examples[<span class="hljs-string">&#x27;summary&#x27;</span>],<br>                max_length=<span class="hljs-number">128</span>,<br>                truncation=<span class="hljs-literal">True</span>,<br>            )[<span class="hljs-string">&#x27;input_ids&#x27;</span>]<br><br>        <span class="hljs-keyword">return</span> data<br><br>    dataset = dataset.<span class="hljs-built_in">map</span>(function=f,<br>                          batched=<span class="hljs-literal">True</span>,<br>                          batch_size=<span class="hljs-number">1000</span>,<br>                          num_proc=<span class="hljs-number">4</span>,<br>                          remove_columns=[<span class="hljs-string">&#x27;document&#x27;</span>, <span class="hljs-string">&#x27;summary&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>])<br><br>    <span class="hljs-keyword">return</span> dataset<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    dataset = get_dataset()<br>    dataset.push_to_hub(repo_id=repo_id, token=hub_token)<br><br><span class="hljs-comment">#直接使用我处理好的数据集</span><br>dataset = load_dataset(path=repo_id)<br><br><span class="hljs-built_in">print</span>(dataset, dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203175450665-20231203%2017:54:50.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203175450665" style="zoom:50%;" />

<h3 id="定义批处理函数"><a href="#定义批处理函数" class="headerlink" title="定义批处理函数"></a>定义批处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#这个函数和下面这个工具类等价,但我也是模仿实现的,不确定有没有出入</span><br><span class="hljs-comment">#from transformers import DataCollatorForSeq2Seq</span><br><span class="hljs-comment">#DataCollatorForSeq2Seq(tokenizer, model=model)</span><br><br><span class="hljs-keyword">import</span> torch<br><br><br><span class="hljs-comment">#数据批处理函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-comment">#求最长的label</span><br>    max_length = <span class="hljs-built_in">max</span>([<span class="hljs-built_in">len</span>(i[<span class="hljs-string">&#x27;labels&#x27;</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])<br><br>    <span class="hljs-comment">#把所有的label都补pad到最长</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data:<br>        pads = [-<span class="hljs-number">100</span>] * (max_length - <span class="hljs-built_in">len</span>(i[<span class="hljs-string">&#x27;labels&#x27;</span>]))<br>        i[<span class="hljs-string">&#x27;labels&#x27;</span>] = i[<span class="hljs-string">&#x27;labels&#x27;</span>] + pads<br><br>    <span class="hljs-comment">#把多个数据整合成一个tensor</span><br>    data = tokenizer.pad(<br>        encoded_inputs=data,<br>        padding=<span class="hljs-literal">True</span>,<br>        max_length=<span class="hljs-literal">None</span>,<br>        pad_to_multiple_of=<span class="hljs-literal">None</span>,<br>        return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>,<br>    )<br><br>    <span class="hljs-comment">#定义decoder_input_ids</span><br>    data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>] = torch.zeros_like(data[<span class="hljs-string">&#x27;labels&#x27;</span>],<br>                                                 dtype=torch.long)<br>    data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>][:, <span class="hljs-number">1</span>:] = data[<span class="hljs-string">&#x27;labels&#x27;</span>][:, :-<span class="hljs-number">1</span>]<br>    data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>][data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>] == -<span class="hljs-number">100</span>] = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">return</span> data<br><br><br>data = [&#123;<br>    <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">21603</span>, <span class="hljs-number">10</span>, <span class="hljs-number">37</span>, <span class="hljs-number">3719</span>, <span class="hljs-number">13</span>],<br>    <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>    <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-number">10455</span>, <span class="hljs-number">120</span>, <span class="hljs-number">80</span>]<br>&#125;, &#123;<br>    <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">21603</span>, <span class="hljs-number">10</span>, <span class="hljs-number">7086</span>, <span class="hljs-number">8408</span>, <span class="hljs-number">563</span>],<br>    <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>    <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-number">301</span>, <span class="hljs-number">53</span>, <span class="hljs-number">4074</span>, <span class="hljs-number">1669</span>]<br>&#125;]<br><br>collate_fn(data)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203193540092-20231203%2019:35:40.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203193540092" style="zoom:50%;" />

<h3 id="数据集加载器-3"><a href="#数据集加载器-3" class="headerlink" title="数据集加载器"></a>数据集加载器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#数据加载器</span><br>loader = torch.utils.data.DataLoader(<br>    dataset=dataset[<span class="hljs-string">&#x27;train&#x27;</span>],<br>    batch_size=<span class="hljs-number">8</span>,<br>    collate_fn=collate_fn,<br>    shuffle=<span class="hljs-literal">True</span>,<br>    drop_last=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> data.items():<br>    <span class="hljs-built_in">print</span>(k, v.shape)<br><br><span class="hljs-built_in">len</span>(loader)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203201230805-20231203%2020:12:31.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203201230805" style="zoom:50%;" />

<h3 id="定义模型-3"><a href="#定义模型-3" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM, T5Model, PreTrainedModel, PretrainedConfig<br><br><span class="hljs-comment">#加载模型</span><br><span class="hljs-comment">#model = AutoModelForSeq2SeqLM.from_pretrained(&#x27;t5-small&#x27;)</span><br><br><br><span class="hljs-comment">#定义下游任务模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(<span class="hljs-title class_ inherited__">PreTrainedModel</span>):<br>    config_class = PretrainedConfig<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,config</span>):<br>        <span class="hljs-built_in">super</span>().__init__(config)<br>        self.pretrained = T5Model.from_pretrained(<span class="hljs-string">&#x27;t5-small&#x27;</span>)<br><br>        <span class="hljs-comment">#本来应该写tokenizer.vocab_size=32100就可以了。</span><br>        <span class="hljs-comment">#但是预训练模型里的参数是32128，所以为了方便就直接使用这个尺寸了</span><br>        self.fc = torch.nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">32128</span>, bias=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-comment">#加载预训练模型的参数</span><br>        parameters = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&#x27;t5-small&#x27;</span>)<br>        self.fc.load_state_dict(parameters.lm_head.state_dict())<br><br>        self.criterion = torch.nn.CrossEntropyLoss(ignore_index=-<span class="hljs-number">100</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, attention_mask, labels, decoder_input_ids</span>):<br><br>        logits = self.pretrained.encoder(input_ids=input_ids,<br>                                         attention_mask=attention_mask)<br><br>        logits = logits.last_hidden_state<br><br>        logits = self.pretrained.decoder(<br>            input_ids=decoder_input_ids,<br>            encoder_hidden_states=logits,<br>            encoder_attention_mask=attention_mask,<br>        )<br><br>        logits = logits.last_hidden_state<br><br>        logits = logits * (<span class="hljs-number">512</span>**-<span class="hljs-number">0.5</span>)<br><br>        logits = self.fc(logits)<br><br>        loss = self.criterion(logits.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">32128</span>), labels.reshape(-<span class="hljs-number">1</span>))<br><br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss, <span class="hljs-string">&#x27;logits&#x27;</span>: logits&#125;<br><br><br>model = Model(PretrainedConfig())<br><br><span class="hljs-comment">#统计参数量</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sum</span>(i.numel() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> model.parameters()) / <span class="hljs-number">10000</span>)<br><br><span class="hljs-comment">#模型试算</span><br>out = model(**data)<br><br>out[<span class="hljs-string">&#x27;loss&#x27;</span>], out[<span class="hljs-string">&#x27;logits&#x27;</span>].shape<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203201339715-20231203%2020:13:39.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203201339715" style="zoom:50%;" />

<h3 id="定义测试函数-2"><a href="#定义测试函数-2" class="headerlink" title="定义测试函数"></a>定义测试函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#测试</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-comment">#数据加载器</span><br>    loader_test = torch.utils.data.DataLoader(<br>        dataset=dataset[<span class="hljs-string">&#x27;test&#x27;</span>],<br>        batch_size=<span class="hljs-number">4</span>,<br>        collate_fn=collate_fn,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">True</span>,<br>    )<br><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader_test):<br>        <span class="hljs-keyword">break</span><br>        <br>    <span class="hljs-comment">#计算</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        out = model(**data)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>        input_ids = tokenizer.decode(data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][i])<br>        pred = tokenizer.decode(out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>)[i]),<br>        label = tokenizer.decode(data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>][i])<br><br>        <span class="hljs-comment">#print(&#x27;input_ids=&#x27;, input_ids)</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pred=&#x27;</span>, pred)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;label=&#x27;</span>, label)<br>        <span class="hljs-built_in">print</span>()<br>        <br></code></pre></td></tr></table></figure>

<h3 id="训练-3"><a href="#训练-3" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers.trainer_pt_utils <span class="hljs-keyword">import</span> get_parameter_names<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-keyword">from</span> transformers.optimization <span class="hljs-keyword">import</span> get_scheduler<br><br><br><span class="hljs-comment">#训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    <span class="hljs-comment">#一个工具函数,能够获取模型中所有参数的名字列表</span><br>    parameter_names = get_parameter_names(model, [torch.nn.LayerNorm])<br><br>    <span class="hljs-comment">#定义哪些参数参与weight_decay</span><br>    parameter_names = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> parameter_names <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;bias&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> i]<br><br>    <span class="hljs-comment">#根据参数要参与weight_decay来把参数分为两组</span><br>    parameter_names = [<br>        &#123;<br>            <span class="hljs-string">&#x27;params&#x27;</span>:<br>            [p <span class="hljs-keyword">for</span> i, p <span class="hljs-keyword">in</span> model.named_parameters() <span class="hljs-keyword">if</span> i <span class="hljs-keyword">in</span> parameter_names],<br>            <span class="hljs-string">&#x27;weight_decay&#x27;</span>:<br>            <span class="hljs-number">1e-2</span>,<br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&#x27;params&#x27;</span>: [<br>                p <span class="hljs-keyword">for</span> i, p <span class="hljs-keyword">in</span> model.named_parameters()<br>                <span class="hljs-keyword">if</span> i <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> parameter_names<br>            ],<br>            <span class="hljs-string">&#x27;weight_decay&#x27;</span>:<br>            <span class="hljs-number">0.0</span>,<br>        &#125;,<br>    ]<br><br>    <span class="hljs-comment">#定义优化器</span><br>    optimizer = AdamW(parameter_names, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-8</span>, lr=<span class="hljs-number">2e-5</span>)<br><br>    <span class="hljs-comment">#定义lr调整器</span><br>    scheduler = get_scheduler(name=<span class="hljs-string">&#x27;linear&#x27;</span>,<br>                              num_warmup_steps=<span class="hljs-number">0</span>,<br>                              num_training_steps=<span class="hljs-built_in">len</span>(loader),<br>                              optimizer=optimizer)<br><br>    device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br>    model.train()<br>    model.to(device)<br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> data.keys():<br>            data[k] = data[k].to(device)<br>            <br>        out = model(**data)<br>        loss = out[<span class="hljs-string">&#x27;loss&#x27;</span>]<br><br>        loss.backward()<br>        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-number">1.0</span>)<br><br>        optimizer.step()<br>        scheduler.step()<br><br>        optimizer.zero_grad()<br>        model.zero_grad()<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            pred = tokenizer.decode(out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>)[<span class="hljs-number">0</span>]),<br><br>            label = tokenizer.decode(data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>][<span class="hljs-number">0</span>])<br><br>            lr = optimizer.state_dict()[<span class="hljs-string">&#x27;param_groups&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;lr&#x27;</span>]<br>            <span class="hljs-built_in">print</span>(i, loss.item(), lr)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pred=&#x27;</span>, pred)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;label=&#x27;</span>, label)<br>            <span class="hljs-built_in">print</span>()<br><br>    model.to(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    train()<br>    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203201851658-20231203%2020:18:51.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203201851658" style="zoom:50%;" />

<h3 id="测试-3"><a href="#测试-3" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#直接使用我训练好的模型</span><br>model = Model.from_pretrained(repo_id)<br><br>test()<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203202338158-20231203%2020:23:38.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203202338158" style="zoom:50%;" />

<h2 id="5、翻译"><a href="#5、翻译" class="headerlink" title="5、翻译"></a>5、翻译</h2><h3 id="定义全局变量-4"><a href="#定义全局变量-4" class="headerlink" title="定义全局变量"></a>定义全局变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#全局变量</span><br>hub_token = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/root/hub_token.txt&#x27;</span>).read().strip()<br>repo_id = <span class="hljs-string">&#x27;lansinuote/nlp.7.translation&#x27;</span><br>push_to_hub = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<h3 id="编码器-4"><a href="#编码器-4" class="headerlink" title="编码器"></a>编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br><span class="hljs-comment">#加载编码器</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;Helsinki-NLP/opus-mt-en-ro&#x27;</span>,<br>                                          use_fast=<span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(tokenizer)<br><br><span class="hljs-comment">#编码试算</span><br>tokenizer.batch_encode_plus(<br>    [[<span class="hljs-string">&#x27;Hello, this one sentence!&#x27;</span>, <span class="hljs-string">&#x27;This is another sentence.&#x27;</span>]])<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204241544-20231203%2020:42:41.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204241544" style="zoom:50%;" />

<h3 id="加载数据集-4"><a href="#加载数据集-4" class="headerlink" title="加载数据集"></a>加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataset</span>():<br>    <span class="hljs-comment">#加载数据</span><br>    dataset = load_dataset(path=<span class="hljs-string">&#x27;wmt16&#x27;</span>, name=<span class="hljs-string">&#x27;ro-en&#x27;</span>)<br><br>    <span class="hljs-comment">#采样,数据量太大了跑不动</span><br>    dataset[<span class="hljs-string">&#x27;train&#x27;</span>] = dataset[<span class="hljs-string">&#x27;train&#x27;</span>].shuffle(<span class="hljs-number">1</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">20000</span>))<br>    dataset[<span class="hljs-string">&#x27;validation&#x27;</span>] = dataset[<span class="hljs-string">&#x27;validation&#x27;</span>].shuffle(<span class="hljs-number">1</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>))<br>    dataset[<span class="hljs-string">&#x27;test&#x27;</span>] = dataset[<span class="hljs-string">&#x27;test&#x27;</span>].shuffle(<span class="hljs-number">1</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>))<br><br>    <span class="hljs-comment">#数据预处理</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">data</span>):<br>        <span class="hljs-comment">#取出数据中的en和ro</span><br>        en = [ex[<span class="hljs-string">&#x27;en&#x27;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> data[<span class="hljs-string">&#x27;translation&#x27;</span>]]<br>        ro = [ex[<span class="hljs-string">&#x27;ro&#x27;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> data[<span class="hljs-string">&#x27;translation&#x27;</span>]]<br><br>        <span class="hljs-comment">#源语言直接编码就行了</span><br>        data = tokenizer.batch_encode_plus(en, max_length=<span class="hljs-number">128</span>, truncation=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment">#目标语言在特殊模块中编码</span><br>        <span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():<br>            data[<span class="hljs-string">&#x27;labels&#x27;</span>] = tokenizer.batch_encode_plus(<br>                ro, max_length=<span class="hljs-number">128</span>, truncation=<span class="hljs-literal">True</span>)[<span class="hljs-string">&#x27;input_ids&#x27;</span>]<br><br>        <span class="hljs-keyword">return</span> data<br><br>    dataset = dataset.<span class="hljs-built_in">map</span>(function=preprocess_function,<br>                          batched=<span class="hljs-literal">True</span>,<br>                          batch_size=<span class="hljs-number">1000</span>,<br>                          num_proc=<span class="hljs-number">4</span>,<br>                          remove_columns=[<span class="hljs-string">&#x27;translation&#x27;</span>])<br><br>    <span class="hljs-keyword">return</span> dataset<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    dataset = get_dataset()<br>    dataset.push_to_hub(repo_id=repo_id, token=hub_token)<br><br><span class="hljs-comment">#直接使用我处理好的数据集</span><br>dataset = load_dataset(path=repo_id)<br><br><span class="hljs-built_in">print</span>(dataset, dataset[<span class="hljs-string">&#x27;train&#x27;</span>][<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204436061-20231203%2020:44:36.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204436061" style="zoom:50%;" />

<h3 id="定义批处理函数-1"><a href="#定义批处理函数-1" class="headerlink" title="定义批处理函数"></a>定义批处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#这个函数和下面这个工具类等价,但我也是模仿实现的,不确定有没有出入</span><br><span class="hljs-comment">#from transformers import DataCollatorForSeq2Seq</span><br><span class="hljs-comment">#DataCollatorForSeq2Seq(tokenizer, model=model)</span><br><br><span class="hljs-keyword">import</span> torch<br><br><br><span class="hljs-comment">#数据批处理函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-comment">#求最长的label</span><br>    max_length = <span class="hljs-built_in">max</span>([<span class="hljs-built_in">len</span>(i[<span class="hljs-string">&#x27;labels&#x27;</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])<br><br>    <span class="hljs-comment">#把所有的label都补pad到最长</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data:<br>        pads = [-<span class="hljs-number">100</span>] * (max_length - <span class="hljs-built_in">len</span>(i[<span class="hljs-string">&#x27;labels&#x27;</span>]))<br>        i[<span class="hljs-string">&#x27;labels&#x27;</span>] = i[<span class="hljs-string">&#x27;labels&#x27;</span>] + pads<br><br>    <span class="hljs-comment">#把多个数据整合成一个tensor</span><br>    data = tokenizer.pad(<br>        encoded_inputs=data,<br>        padding=<span class="hljs-literal">True</span>,<br>        max_length=<span class="hljs-literal">None</span>,<br>        pad_to_multiple_of=<span class="hljs-literal">None</span>,<br>        return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>,<br>    )<br><br>    <span class="hljs-comment">#定义decoder_input_ids</span><br>    data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>] = torch.full_like(data[<span class="hljs-string">&#x27;labels&#x27;</span>],<br>                                                tokenizer.get_vocab()[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>],<br>                                                dtype=torch.long)<br>    data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>][:, <span class="hljs-number">1</span>:] = data[<span class="hljs-string">&#x27;labels&#x27;</span>][:, :-<span class="hljs-number">1</span>]<br>    data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>][data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>] ==<br>                              -<span class="hljs-number">100</span>] = tokenizer.get_vocab()[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]<br><br>    <span class="hljs-keyword">return</span> data<br><br><br>data = [&#123;<br>    <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">21603</span>, <span class="hljs-number">10</span>, <span class="hljs-number">37</span>, <span class="hljs-number">3719</span>, <span class="hljs-number">13</span>],<br>    <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>    <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-number">10455</span>, <span class="hljs-number">120</span>, <span class="hljs-number">80</span>]<br>&#125;, &#123;<br>    <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">21603</span>, <span class="hljs-number">10</span>, <span class="hljs-number">7086</span>, <span class="hljs-number">8408</span>, <span class="hljs-number">563</span>],<br>    <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>    <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-number">301</span>, <span class="hljs-number">53</span>, <span class="hljs-number">4074</span>, <span class="hljs-number">1669</span>]<br>&#125;]<br><br>collate_fn(data)[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>]<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204518582-20231203%2020:45:18.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204518582" style="zoom:50%;" />

<h3 id="数据集加载器-4"><a href="#数据集加载器-4" class="headerlink" title="数据集加载器"></a>数据集加载器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment">#数据加载器</span><br>loader = torch.utils.data.DataLoader(<br>    dataset=dataset[<span class="hljs-string">&#x27;train&#x27;</span>],<br>    batch_size=<span class="hljs-number">8</span>,<br>    collate_fn=collate_fn,<br>    shuffle=<span class="hljs-literal">True</span>,<br>    drop_last=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>    <span class="hljs-keyword">break</span><br><br><span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> data.items():<br>    <span class="hljs-built_in">print</span>(k, v.shape, v[:<span class="hljs-number">2</span>])<br><br><span class="hljs-built_in">len</span>(loader)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204557017-20231203%2020:45:57.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204557017" style="zoom:50%;" />

<h3 id="定义模型-4"><a href="#定义模型-4" class="headerlink" title="定义模型"></a>定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM, MarianModel, PreTrainedModel, PretrainedConfig<br><br><span class="hljs-comment">#加载模型</span><br><span class="hljs-comment">#model = AutoModelForSeq2SeqLM.from_pretrained(&#x27;Helsinki-NLP/opus-mt-en-ro&#x27;)</span><br><br><br><span class="hljs-comment">#定义下游任务模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(<span class="hljs-title class_ inherited__">PreTrainedModel</span>):<br>    config_class = PretrainedConfig<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-built_in">super</span>().__init__(config)<br>        self.pretrained = MarianModel.from_pretrained(<br>            <span class="hljs-string">&#x27;Helsinki-NLP/opus-mt-en-ro&#x27;</span>)<br><br>        self.register_buffer(<span class="hljs-string">&#x27;final_logits_bias&#x27;</span>,<br>                             torch.zeros(<span class="hljs-number">1</span>, tokenizer.vocab_size))<br><br>        self.fc = torch.nn.Linear(<span class="hljs-number">512</span>, tokenizer.vocab_size, bias=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-comment">#加载预训练模型的参数</span><br>        parameters = AutoModelForSeq2SeqLM.from_pretrained(<br>            <span class="hljs-string">&#x27;Helsinki-NLP/opus-mt-en-ro&#x27;</span>)<br>        self.fc.load_state_dict(parameters.lm_head.state_dict())<br><br>        self.criterion = torch.nn.CrossEntropyLoss()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, attention_mask, labels, decoder_input_ids</span>):<br>        logits = self.pretrained(input_ids=input_ids,<br>                                 attention_mask=attention_mask,<br>                                 decoder_input_ids=decoder_input_ids)<br>        logits = logits.last_hidden_state<br><br>        logits = self.fc(logits) + self.final_logits_bias<br><br>        loss = self.criterion(logits.flatten(end_dim=<span class="hljs-number">1</span>), labels.flatten())<br><br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss, <span class="hljs-string">&#x27;logits&#x27;</span>: logits&#125;<br><br><br>model = Model(PretrainedConfig())<br><br><span class="hljs-comment">#统计参数量</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sum</span>(i.numel() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> model.parameters()) / <span class="hljs-number">10000</span>)<br><br>out = model(**data)<br><br>out[<span class="hljs-string">&#x27;loss&#x27;</span>], out[<span class="hljs-string">&#x27;logits&#x27;</span>].shape<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204639161-20231203%2020:46:39.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204639161" style="zoom:50%;" />

<h3 id="加载评价函数"><a href="#加载评价函数" class="headerlink" title="加载评价函数"></a>加载评价函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric<br><br><span class="hljs-comment">#加载评价函数</span><br>metric = load_metric(path=<span class="hljs-string">&#x27;sacrebleu&#x27;</span>)<br><br><span class="hljs-comment">#试算</span><br>metric.compute(predictions=[<span class="hljs-string">&#x27;hello there&#x27;</span>, <span class="hljs-string">&#x27;general kenobi&#x27;</span>],<br>               references=[[<span class="hljs-string">&#x27;hello there&#x27;</span>], [<span class="hljs-string">&#x27;general kenobi&#x27;</span>]])<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204714988-20231203%2020:47:15.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204714988" style="zoom:50%;" />

<h3 id="定义测试函数-3"><a href="#定义测试函数-3" class="headerlink" title="定义测试函数"></a>定义测试函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#测试</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    model.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-comment">#数据加载器</span><br>    loader_test = torch.utils.data.DataLoader(<br>        dataset=dataset[<span class="hljs-string">&#x27;test&#x27;</span>],<br>        batch_size=<span class="hljs-number">8</span>,<br>        collate_fn=collate_fn,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">True</span>,<br>    )<br><br>    predictions = []<br>    references = []<br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader_test):<br>        <span class="hljs-comment">#计算</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            out = model(**data)<br><br>        pred = tokenizer.batch_decode(out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>))<br>        label = tokenizer.batch_decode(data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>])<br>        predictions.extend(pred)<br>        references.extend(label)<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(i)<br>            input_ids = tokenizer.decode(data[<span class="hljs-string">&#x27;input_ids&#x27;</span>][<span class="hljs-number">0</span>])<br><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;input_ids=&#x27;</span>, input_ids)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pred=&#x27;</span>, pred[<span class="hljs-number">0</span>])<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;label=&#x27;</span>, label[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">10</span>:<br>            <span class="hljs-keyword">break</span><br><br>    references = [[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> references]<br>    metric_out = metric.compute(predictions=predictions, references=references)<br>    <span class="hljs-built_in">print</span>(metric_out)<br><br></code></pre></td></tr></table></figure>

<h3 id="训练-4"><a href="#训练-4" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-keyword">from</span> transformers.optimization <span class="hljs-keyword">import</span> get_scheduler<br><br><br><span class="hljs-comment">#训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)<br>    scheduler = get_scheduler(name=<span class="hljs-string">&#x27;linear&#x27;</span>,<br>                              num_warmup_steps=<span class="hljs-number">0</span>,<br>                              num_training_steps=<span class="hljs-built_in">len</span>(loader),<br>                              optimizer=optimizer)<br><br>    device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br>    model.train()<br>    model.to(device)<br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(loader):<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> data.keys():<br>            data[k] = data[k].to(device)<br>    <br>        out = model(**data)<br>        loss = out[<span class="hljs-string">&#x27;loss&#x27;</span>]<br><br>        loss.backward()<br>        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-number">1.0</span>)<br><br>        optimizer.step()<br>        scheduler.step()<br><br>        optimizer.zero_grad()<br>        model.zero_grad()<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            out = out[<span class="hljs-string">&#x27;logits&#x27;</span>].argmax(dim=<span class="hljs-number">2</span>)<br>            correct = (data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>] == out).<span class="hljs-built_in">sum</span>().item()<br>            total = data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>].shape[<span class="hljs-number">1</span>] * <span class="hljs-number">8</span><br>            accuracy = correct / total<br>            <span class="hljs-keyword">del</span> correct<br>            <span class="hljs-keyword">del</span> total<br><br>            predictions = []<br>            references = []<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):<br>                pred = tokenizer.decode(out[j])<br>                label = tokenizer.decode(data[<span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>][j])<br>                predictions.append(pred)<br>                references.append([label])<br><br>            metric_out = metric.compute(predictions=predictions,<br>                                        references=references)<br><br>            lr = optimizer.state_dict()[<span class="hljs-string">&#x27;param_groups&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;lr&#x27;</span>]<br><br>            <span class="hljs-built_in">print</span>(i, loss.item(), accuracy, metric_out, lr)<br><br>    model.to(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> push_to_hub:<br>    train()<br>    model.push_to_hub(repo_id=repo_id, use_auth_token=hub_token)<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204830305-20231203%2020:48:30.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204830305" style="zoom:50%;" />

<h3 id="测试-4"><a href="#测试-4" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#直接使用我训练好的模型</span><br>model = Model.from_pretrained(repo_id)<br><br>test()<br></code></pre></td></tr></table></figure>

<img src="https://cdn.jsdelivr.net/gh/Yoonalis/img@master/blog/image-20231203204917631-20231203%2020:49:17.png" srcset="/blog/img/loading.gif" lazyload alt="image-20231203204917631" style="zoom:50%;" />
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/blog/categories/%E8%AE%BA%E6%96%87/" class="category-chain-item">论文</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/blog/tags/%E8%AE%BA%E6%96%87%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%81nlp%E3%80%81huggingface/">#论文、深度学习、nlp、huggingface</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>HuggingFace NLP Tasks</div>
      <div>https://yoonalis.github.io/blog/2023/12/01/HuggingFace NLP Tasks/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Azure</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年12月1日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/blog/2023/12/01/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/" title="经典论文">
                        <span class="hidden-mobile">经典论文</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/blog/js/events.js" ></script>
<script  src="/blog/js/plugins.js" ></script>


  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/blog/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/blog/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/caidai.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/love.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/blog/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
